{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【第２回目　課題4】 PyTorchを使った深層学習 (4): ImageNet 学習済モデルの利用．DCNN特徴抽出とファインチューニング．\n",
    "\n",
    "PyTorchでは，<a href=\"https://pytorch.org/docs/stable/torchvision/models.html\">TORCHVISION MODELS</a> を使うことで，ImageNetの学習済モデルが簡単に利用できます．\n",
    "\n",
    "### <a href=\"https://pytorch.org/docs/stable/torchvision/models.html\">学習済モデル自動読み込み</a>\n",
    "torchvision.datasets と同様に，自動ダウンロード機能を備えた torchvision.modelsのモジュール群が用意されています．\n",
    "* AlexNet\n",
    "* VGG（定番のVGG．パラメータが512MBもあって巨大なのが難点．)\n",
    "* ResNet\n",
    "* SqueezeNet\n",
    "* DenseNet\n",
    "* Inception v3\n",
    "* GoogLeNet\n",
    "* ShuffleNet v2\n",
    "* MobileNet v2 (Googleのモバイル用ネットワーク．パラメータが10MB未満．）\n",
    "* ResNeXt\n",
    "* Wide ResNet\n",
    "* MNASNet (最新の自動構築されたモバイル用ネットワーク) <a href=\"https://arxiv.org/abs/1807.11626\">(Mobile Neural Archtecture Search Network)\n",
    "    \n",
    "初回実行時には，datasetsと同様に自動的にダウンロードが行われます．（ですので，Proxyが必要な環境では，事前に環境変数を設定する必要があります．)\n",
    "\n",
    "他にも，object detection, semantic segmentation, video classification のモデルが用意されています．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "import os\n",
    "\n",
    "# proxyの設定．\n",
    "# keras.datasetsでは，datasetを直接ダウンロードするので，学内マシンからは通常必要．\n",
    "os.environ[\"http_proxy\"] = \"http://proxy.uec.ac.jp:8080/\"\n",
    "os.environ[\"https_proxy\"] = \"http://proxy.uec.ac.jp:8080/\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"      # \"0\":GPU0, \"1\":GPU1, \"0,1\":GPUを2つとも使用\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50 による1000種類分類\n",
    "\n",
    "まずは，ResNet50 のpretrained modelを使って，1000種類認識をしてみましょう．\n",
    "以下のコードだけで実行できます．学習済モデルも自動的にダウンロードするので簡単です．\n",
    "なお，初回実行時は，モデルのダウンロードを行うので，結果が出るまで少し時間が掛かります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet50 による 1000種類分類\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 640564\r\n",
      "-rw------- 1 yamamoto-k YANAI_LAB 102502400 Apr 19 00:11 resnet50-19c8e357.pth\r\n",
      "-rw------- 1 yamamoto-k YANAI_LAB 553433881 Apr 19 00:11 vgg16-397923af.pth\r\n"
     ]
    }
   ],
   "source": [
    "resnet50 = models.resnet50(pretrained=True,progress=True)\n",
    "softmax=nn.Softmax(dim=1)\n",
    "# pretrained=True とすると，学習済みポラメータも読み込まれる．\n",
    "# ~/.cache/torch/checkpoints/ の下に読み込まれます．\n",
    "# ls でダウンロードされていることを確認してみます．\n",
    "! ls -l ~/.cache/torch/checkpoints/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorchのpre-trained modelは，<a href=\"https://discuss.pytorch.org/t/whats-the-range-of-the-input-value-desired-to-use-pretrained-resnet152-and-vgg19/1683\">ここ</a> にかかれているように，画像は [0, 1] で表現されるように変換したものを，さらに，平均[0.485, 0.456, 0.406], 分散[0.229, 0.224, 0.225] となるように変換して学習されています．\n",
    "ですので，[0, 255]で読み込んだ画像を\n",
    "```python\n",
    "mean=np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "std=np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "img=(img/255.0-mean)/std\n",
    "```\n",
    "で，変換してから，学習済モデルに渡してやる必要があります．\n",
    "Pretrained model利用時に，これを行わないと，無意味な認識結果が出力されますので，十分に注意して下さい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img=np.array(Image.open('images/lion.jpg').resize((224,224)), dtype=np.float32)\n",
    "mean=np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "std=np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "img=(img/255.0-mean)/std\n",
    "img=img.transpose(2,0,1)  # HWC -> CHW\n",
    "img=img[np.newaxis,...]  # adding batch axis\n",
    "img=torch.from_numpy(img)\n",
    "\n",
    "resnet50.eval() \n",
    "# batch_normalization を eval modelで計算するために，model.eval()で\n",
    "# eval modeを設定する．(学習時の平均分散を利用．)　\n",
    "# train modeだと，batch内の平均分散が使われるが，\n",
    "# この場合 batch_size=1 でbatch内平均分散が計算され，正しくない結果になる．\n",
    "# batch normalization を使ったモデルで認識する場合は，evel modeへの\n",
    "# 切り替えは必須なので，注意すること．\n",
    "\n",
    "with torch.no_grad(): # 勾配計算はしないので，no_grad modeで計算\n",
    "    out=softmax(resnet50(img)).numpy()[0]\n",
    "    # numpy()で，Tensor形式から numpy形式に変換\n",
    "    # batch_size=1 で1枚だけ認識したので，1枚目の結果だけをoutに入れるために[0]がついている\n",
    "\n",
    "top5   =np.sort(out)[:-6:-1]      # 昇順にソートされるので，最後の5つが top5\n",
    "top5idx=np.argsort(out)[:-6:-1]   # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.99926358 n02129165 lion, king of beasts, Panthera leo\n",
      "[2] 0.00011419 n02125311 cougar, puma, catamount, mountain lion, painter, panther, Felis concolor\n",
      "[3] 0.00009945 n02117135 hyena, hyaena\n",
      "[4] 0.00006722 n02397096 warthog\n",
      "[5] 0.00005424 n02422106 hartebeest\n"
     ]
    }
   ],
   "source": [
    "# 認識結果の top-5 の結果の表示\n",
    "SYNSET_FILE='images/synset_words.txt'  # ImageNet1000 種類のカテゴリ名が書かれたファイル．\n",
    "synset=open(SYNSET_FILE).read().split('\\n')\n",
    "for i in range(5):\n",
    "    print(\"[%d] %.8f %s\" % (i+1,top5[i],synset[top5idx[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に TorchVision を使った方法です．こちらの方が簡単です．\n",
    "\n",
    "TorchVision を使う場合は，以下の様にnormalizeします．\n",
    "```python\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.99930012 n02129165 lion, king of beasts, Panthera leo\n",
      "[2] 0.00013924 n02125311 cougar, puma, catamount, mountain lion, painter, panther, Felis concolor\n",
      "[3] 0.00006286 n02117135 hyena, hyaena\n",
      "[4] 0.00005809 n02422106 hartebeest\n",
      "[5] 0.00005807 n02130308 cheetah, chetah, Acinonyx jubatus\n"
     ]
    }
   ],
   "source": [
    "# 画像の変換は, TorchVisionを使うと簡単にできます．\n",
    "import torchvision.transforms as transforms\n",
    "image_size = (224, 224) \n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "image_transform = transforms.Compose([transforms.Resize(image_size),transforms.ToTensor(),normalize])\n",
    "img = Image.open('images/lion.jpg')\n",
    "img = image_transform(img)\n",
    "img = img.unsqueeze(0)\n",
    "resnet50.eval() \n",
    "with torch.no_grad(): \n",
    "    out=softmax(resnet50(img)).numpy()[0]\n",
    "top5   =np.sort(out)[:-6:-1]   \n",
    "top5idx=np.argsort(out)[:-6:-1] \n",
    "for i in range(5):\n",
    "    print(\"[%d] %.8f %s\" % (i+1,top5[i],synset[top5idx[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50 のネットワークを表示してみます．各res blockにskip connectionが入っていること(addのconnected to をたどってみましょう．)と，ネットワークの最後にGlobalAveragePooling (出力のfeature mapが 1x1 になっています), Flatten, Denseが入っていることを確認しましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ResNet50 の表示\n",
    "print(resnet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 を使った特徴抽出\n",
    "\n",
    "VGG16 の fc2 から 4096次元特徴ベクトルを抽出してみましょう．\n",
    "初回実行時は，モデルのダウンロードを行うので，結果が出るまで少し時間が掛かります．\n",
    "\n",
    "4096次元ベクトルは，類似画像検索や，SVMを用いた画像分類の特徴量として利用できます．なお，画像分類は後述するfine-tuningでも可能で，一般にはそちらの方が高精度ですが，学習にはGPUが必要で時間が掛かるので，CPUのみで実行可能なSVMを使った画像分類の学習も場合によっては有用です．\n",
    "\n",
    "なお，データセットは，<a href=\"http://mm.cs.uec.ac.jp/animal.zip\">動物10種各100枚</a>を使ってください．\n",
    "Jupyter の terminal を開いて，Jupyterの作業ディレクトリに展開してください．\n",
    "```\n",
    "setenv http_proxy http://proxy.uec.ac.jp:8080/\n",
    "wget http://mm.cs.uec.ac.jp/animal.zip\n",
    "unzip animal.zip\n",
    "```\n",
    "としてください．(実行セルで， !(linux コマンド) としても実行できます．)\n",
    "\n",
    "なお，IEDの場合は /usr/local/class/object/animal, CEDの場合は/ced-home/staff/yanai/media/animal に同じデータセットがありますので，フルパス名を指定すれば，ダウンロード不要です．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: setenv: not found\n",
      "--2021-04-19 01:33:23--  http://mm.cs.uec.ac.jp/animal.zip\n",
      "Resolving proxy.uec.ac.jp (proxy.uec.ac.jp)... 130.153.8.24\n",
      "Connecting to proxy.uec.ac.jp (proxy.uec.ac.jp)|130.153.8.24|:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 34751138 (33M) [application/zip]\n",
      "Saving to: 'animal.zip.2'\n",
      "\n",
      "animal.zip.2        100%[===================>]  33.14M  42.7MB/s    in 0.8s    \n",
      "\n",
      "2021-04-19 01:33:25 (42.7 MB/s) - 'animal.zip.2' saved [34751138/34751138]\n",
      "\n",
      "Archive:  animal.zip\n",
      "replace animal/whale/314068.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!setenv http_proxy http://proxy.uec.ac.jp:8080/\n",
    "!wget http://mm.cs.uec.ac.jp/animal.zip\n",
    "!unzip animal.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 640564\r\n",
      "-rw------- 1 yamamoto-k YANAI_LAB 102502400 Apr 19 00:11 resnet50-19c8e357.pth\r\n",
      "-rw------- 1 yamamoto-k YANAI_LAB 553433881 Apr 19 00:11 vgg16-397923af.pth\r\n"
     ]
    }
   ],
   "source": [
    "vgg16 = models.vgg16(pretrained=True,progress=True)\n",
    "softmax=nn.Softmax(dim=1)\n",
    "# pretrained=True とすると，学習済みポラメータも読み込まれる．\n",
    "# ~/.cache/torch/checkpoints/ に読み込まれます．VGG16は550MBもあるので，不要になったら消去しましょう．\n",
    "# ls でダウンロードされていることを確認してみます．\n",
    "! ls -l ~/.cache/torch/checkpoints/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.99754685 n02129165 lion, king of beasts, Panthera leo\n",
      "[2] 0.00033962 n02112137 chow, chow chow\n",
      "[3] 0.00028383 n02115913 dhole, Cuon alpinus\n",
      "[4] 0.00026045 n02106030 collie\n",
      "[5] 0.00013270 n02410509 bison\n"
     ]
    }
   ],
   "source": [
    "# 念のため，認識してみます．\n",
    "# 2位以下はResNetと若干異なっていますが，1位はあっているはずです．\n",
    "image_size = (224, 224) \n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "image_transform = transforms.Compose([transforms.Resize(image_size),transforms.ToTensor(),normalize])\n",
    "img = Image.open('images/lion.jpg')\n",
    "img = image_transform(img)\n",
    "img = img.unsqueeze(0)\n",
    "vgg16.eval() \n",
    "with torch.no_grad():\n",
    "    out=softmax(vgg16(img)).numpy()[0]\n",
    "top5   =np.sort(out)[:-6:-1]   \n",
    "top5idx=np.argsort(out)[:-6:-1] \n",
    "for i in range(5):\n",
    "    print(\"[%d] %.8f %s\" % (i+1,top5[i],synset[top5idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (2): Flatten()\n",
      "  (3): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=4096, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.reshape(input.size(0), -1)\n",
    "    \n",
    "vgg16fc7 = torch.nn.Sequential(\n",
    "    vgg16.features,\n",
    "    vgg16.avgpool,\n",
    "    Flatten(),\n",
    "    *list(vgg16.classifier.children())[:-3]  # 最後の3つのlayer(relu,dropout,fc1000)を削除\n",
    ")\n",
    "# 表示してみます．fc7 (fc4096)が最終出力になっているはずです．\n",
    "print(vgg16fc7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4096])\n",
      "tensor([-0.4661, -2.8360, -3.2846,  0.6673, -1.7138, -4.5680,  1.4430, -1.3399,\n",
      "        -1.5306,  1.4850, -1.2114,  0.0782,  0.2708, -0.5227, -2.2403, -1.6590,\n",
      "        -1.8959, -1.2780, -1.6734, -0.1346, -3.0772, -2.9543, -2.2964,  0.0534,\n",
      "        -0.7952,  4.3078, -2.4280,  1.2097, -0.9758,  1.4676, -0.4221, -0.6301,\n",
      "        -1.3490, -0.1666, -2.0901, -1.1264, -1.8081, -2.0467, -2.2239, -3.1684,\n",
      "         0.2978, -1.4273,  0.6979, -2.1675, -1.2621,  0.3755,  4.6138,  0.1551,\n",
      "        -1.8192, -4.0548, -3.1900,  0.8393, -3.8521, -1.2662,  1.3195, -3.0540,\n",
      "        -0.9008, -2.7653, -0.1400, -2.2235, -1.8330, -0.7277,  1.0339, -1.2487,\n",
      "        -1.7718, -1.4427, -1.8328, -1.7777, -2.6309, -1.0341, -3.1651, -1.8286,\n",
      "         0.6546, -2.0965, -2.3978,  0.9357, -1.8812, -2.3502, -0.4309, -1.3155,\n",
      "        -2.1128, -2.8751, -3.5441, -1.5315, -2.1354,  0.0543, -3.0295, -2.0644,\n",
      "        -0.2059, -0.8311, -2.8010,  0.2827,  0.5275, -2.9884, -0.3949, -0.4119,\n",
      "        -0.6293, -3.3932, -2.0517,  0.7137])\n"
     ]
    }
   ],
   "source": [
    "vgg16fc7.eval()\n",
    "with torch.no_grad():\n",
    "    fc7=vgg16fc7(img)\n",
    "print(fc7.shape)     # shapeの表示\n",
    "print(fc7[0][0:100]) # fc7特徴量を最初の100次元分だけ表示してみます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に学習画像の読み込みです．DataLoaderを使う方法もありますが，ここでは一気に2クラス分の200枚読み込んで，まとめてfc7特徴を抽出してしまいましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 0th image\n",
      "reading 100th image\n",
      "(200, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "# imglist に cat100枚，dog100枚の合計200枚分のファイル名を用意します．\n",
    "# cat dog elephant fish horse lion penguin tiger whale wildcat があります．\n",
    "imglist=glob.glob('animal/lion/*.jpg')+glob.glob('animal/tiger/*.jpg')\n",
    "\n",
    "# 200枚画像をimgsに読み込みます．\n",
    "in_size=224\n",
    "imgs = np.empty((0,in_size,in_size,3), dtype=np.float32)\n",
    "\n",
    "for i,img_path in enumerate(imglist):\n",
    "    if i%100==0:\n",
    "        print(\"reading {}th image\".format(i))\n",
    "    x = np.array(Image.open(img_path).resize((in_size,in_size)), dtype=np.float32)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    imgs = np.vstack((imgs,x))\n",
    "    \n",
    "mean=np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "std=np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "imgs=(imgs/255.0-mean)/std\n",
    "imgs=imgs.transpose(0,3,1,2)  # HWC -> CHW\n",
    "img=torch.from_numpy(imgs)\n",
    "print(imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 200枚処理するので，GPUを使います．\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "vgg16fc7 = vgg16fc7.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 4096)\n"
     ]
    }
   ],
   "source": [
    "vgg16fc7.eval()\n",
    "with torch.no_grad():\n",
    "    fc=vgg16fc7(img.to(device)).cpu().numpy()\n",
    "    # gpuで処理した結果を cpuに戻して，numpy形式にします．\n",
    "print(fc.shape)     # shapeの表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下では，抽出したfc特徴を，5-fold cross validationで学習・評価します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=100.00000%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    " \n",
    "# 分類器のオブジェクトを生成．\n",
    "# Cはソフトマージンのハイパーパラメータです．\n",
    "model_svm = LinearSVC(C=1.0)\n",
    "num = len(fc)\n",
    "label=np.append(np.ones(num//2,dtype=np.float32),(-1)*np.ones(num//2,dtype=np.float32))\n",
    "acc=[]\n",
    "\n",
    "# 5 cross validation で分類精度評価\n",
    "for f in range(5):\n",
    "    # indexの作成．5で割ってf余る数がtestのindex, そうでない数がtrainのindex.\n",
    "    train=[n for n in range(num) if n%5!=f]\n",
    "    test =[n for n in range(num) if n%5==f]\n",
    "\n",
    "# トレーニングデータで学習する\n",
    "# label は 0,1のベクトルになります．\n",
    "    model_svm.fit(fc[train], label[train])\n",
    " \n",
    "# テストデータの分類をする\n",
    "#label_predict = model.predict(fc[test])  #0/1分類\n",
    "#predict_score = model.decision_function(fc[test]) #超平面からの符号つき距離\n",
    "    acc.append(model_svm.score(fc[test],label[test])) # 分類＋accuracyの計算\n",
    "    \n",
    "    # print('accuracy={:.5%}'.format(model_svm.score(fc[test],label[test])))\n",
    "print('accuracy={:.5%}'.format(np.average(acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 のファインチューニングによる小規模データセットの学習\n",
    "\n",
    "VGG16の学習済畳み込み層を使って，小規模画像データセットの学習を行ってみましょう．\n",
    "\n",
    "データセットは同じく動物データを使いますが，ここでは10クラスのマルチクラス分類を行います．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今度は，ImageLoaderを使ってみましょう．\n",
    "\n",
    "クラスごとにサブディレクトリが別れている場合は，<a href=\"https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder\">torchvision.datasets.ImageFolder</a>を使って，簡単に dataset objectを生成できます．ラベルデータも同時に作成してくれるので，手間が省けます．\n",
    "\n",
    "次に，<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.Subset\">torch.utils.data.Subset</a>を使って，train/testにdatasetを分割します．\n",
    "\n",
    "あとは，MNISTの時と同じで，train/testの<a href=\"https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\">DataLoader</a>を生成します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まず，image_transform を定義します．ImageFolderで指定するので，先に\n",
    "# 定義しておく必要があります．\n",
    "\n",
    "imgdir=\"./animal\"\n",
    "\n",
    "# リサイズ，CHW変換，正規化 の標準的な image_transform\n",
    "image_size = (224, 224) \n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "image_transform = transforms.Compose([transforms.Resize(image_size),transforms.ToTensor(),normalize])\n",
    "\n",
    "# リサイズ，CHW変換，正規化 に加えて，+-20度のランダム回転，\n",
    "# 0.8-1.2倍のランダム縦横比変換＋0.7-1.0倍のランダムクロップ，ランダム左右反転，のデータ拡張ありの image_transform\n",
    "image_transform_aug = transforms.Compose([transforms.RandomRotation(20),\n",
    "                                          transforms.RandomResizedCrop(image_size, scale=(0.7, 1.0), ratio=(0.8, 1.2)),\n",
    "                                          transforms.RandomHorizontalFlip(), transforms.ToTensor(), normalize\n",
    "                                        ])\n",
    "\n",
    "# ImageFolfer では，クラス毎にディレクトリがあって，そのクラスの画像が入っていることを想定しています．\n",
    "# animal/lion/*.jpg, animal/dog/*.jpg, animal/cat/*.jpg  ....のような感じです．\n",
    "#   animal datasetは，まさにそのようになっています．\n",
    "dataset=torchvision.datasets.ImageFolder(root=imgdir, transform=image_transform) \n",
    "\n",
    "# データ拡張ありの場合は，以下のを用いる． image_transform -> image_transform_aug\n",
    "augmentation=True # データ拡張しない場合は False，拡張する場合は True にする．\n",
    "\n",
    "if augmentation:\n",
    "    # データ拡張あり (学習データのみ)\n",
    "    dataset2=torchvision.datasets.ImageFolder(root=imgdir, transform=image_transform_aug) \n",
    "else:\n",
    "    # データ拡張なし\n",
    "    dataset2=dataset\n",
    "    \n",
    "num = len(dataset) # animal datasetの場合，1000\n",
    "\n",
    "# indexの作成．5で割り切れない数がtestのindex, 5の倍数がtrainのindex.\n",
    "# つまり，train:text=4:1=80%:20% とする．\n",
    "train_idx=[n for n in range(num) if n%5!=0]\n",
    "test_idx =[n for n in range(num) if n%5==0]\n",
    "\n",
    "trainset  = torch.utils.data.dataset.Subset(dataset2, train_idx)\n",
    "testset   = torch.utils.data.dataset.Subset(dataset, test_idx)\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次は，モデル定義です．\n",
    "\n",
    "VGG16を畳み込み層だけ読み込んだモデルvgg16と，その出力を新しく追加しする全結合2層のtop_modelを用意します．\n",
    "さらに，その2つのモデルをModel によって結合します．vgg16の出力をtop_modelの入力として，それを出力とする，vgg_modelを\n",
    "定義します．\n",
    "\n",
    "結果的に，元々のVGG16の全結合層だけを新しく入れ替えて，再学習することになります．vgg_modelの元々の部分は学習済のパラメータが設定されていて，一方，新しい部分はランダム値で初期化されます．\n",
    "\n",
    "このvgg_modelを学習します．ただし，vgg_modelの前半のレイヤーは taininable = False として，学習しないようにします．\n",
    "パラメータの更新が，追加した全結合と，vggの最後の畳み込み層のみになるので，学習時間が大幅に節約できます．\n",
    "\n",
    "このように fine-tuningでは，出力に近い層だけを学習するのが一般的です．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (2): Flatten()\n",
      "  (3): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (7): ReLU(inplace=True)\n",
      "  (8): Dropout(p=0.5, inplace=False)\n",
      "  (9): Linear(in_features=4096, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# vgg16 のconvの学習済パラメータはfinetuneしないように凍結します．\n",
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# finetune用の model の定義．最後のlayerをcutして，nn.Linear(4096,10) を追加\n",
    "model = torch.nn.Sequential(\n",
    "    vgg16.features,\n",
    "    vgg16.avgpool,\n",
    "    Flatten(),\n",
    "    *list(vgg16.classifier.children())[:-1],  # 最後のlayer(fc1000)を削除\n",
    "    nn.Linear(4096,10)\n",
    ")\n",
    "# 表示してみます．10class分のfc出力が最終出力になっているはずです．\n",
    "print(model)\n",
    "\n",
    "# GPUに転送します．\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "課題3と同様に，学習中の経過のグラフ表示用にcallback用のShowGraphクラスを用意します．（ここは中身の理解不要．）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "# callback のクラス ShowGraphを定義\n",
    "class ShowGraph:\n",
    "    def __init__(self,max_epoch):\n",
    "        # 表示エリアの設定\n",
    "        self.fig=plt.figure(figsize=(8,4))\n",
    "        self.fig1 = self.fig.add_subplot(121)\n",
    "        self.fig1.axis([0, max_epoch, 0.5, 1.0])\n",
    "        self.fig1.set_title('accuracy')\n",
    "        self.fig1.set_ylabel('accuracy')\n",
    "        self.fig1.set_xlabel('epoch')\n",
    "        self.fig2 = self.fig.add_subplot(122)\n",
    "        self.fig2.axis([0, max_epoch, 0, 5])\n",
    "        self.fig2.set_title('loss')\n",
    "        self.fig2.set_ylabel('loss')\n",
    "        self.fig2.set_xlabel('epoch')\n",
    "        self.max_epoch=max_epoch\n",
    "        self.start=time.time()\n",
    "    \n",
    "    # 学習の最初に呼び出される\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses=[]\n",
    "        self.losses_val=[]\n",
    "        self.acc=[]\n",
    "        self.acc_val=[]\n",
    "        self.n_epoch=[]\n",
    "        self.n_epoch_v=[]\n",
    "    \n",
    "    # 各epochの最後に呼び出される\n",
    "    def on_epoch_end(self, epoch, loss, acc, vloss, vacc):\n",
    "        self.n_epoch.append(epoch)\n",
    "        self.n_epoch_v.append(epoch)\n",
    "        self.acc.append(acc)\n",
    "        self.acc_val.append(vacc)     \n",
    "        self.losses.append(loss)\n",
    "        self.losses_val.append(vloss)    \n",
    "        self.test_acc=vacc\n",
    "    \n",
    "        display.clear_output(wait = True)\n",
    "        self.fig1.plot(self.n_epoch,self.acc,\"b\")\n",
    "        self.fig1.plot(self.n_epoch_v,self.acc_val,\"r\")\n",
    "        self.fig1.legend(['train', 'test'], loc='upper left')\n",
    "        self.fig2.plot(self.n_epoch,self.losses,\"b\")\n",
    "        self.fig2.plot(self.n_epoch_v,self.losses_val,\"r\")\n",
    "        self.fig2.legend(['train', 'test'], loc='upper right')\n",
    "        display.display(self.fig)\n",
    "        \n",
    "    def on_epoch_train(self, epoch, loss, acc): # validationを評価しないepochの表示用\n",
    "        self.n_epoch.append(epoch)\n",
    "        self.acc.append(acc)\n",
    "        self.losses.append(loss)\n",
    "    \n",
    "        display.clear_output(wait = True)\n",
    "        self.fig1.plot(self.n_epoch,self.acc,\"b\")\n",
    "#        self.fig1.legend(['train', 'test'], loc='upper left')\n",
    "        self.fig2.plot(self.n_epoch,self.losses,\"b\")\n",
    "#        self.fig2.legend(['train', 'test'], loc='upper right')\n",
    "        display.display(self.fig)\n",
    "              \n",
    "    # デストラクタ(オブジェクトが消滅時に実行される)  \n",
    "    # グラフが２つ表示されるのを防止．さらに最終val acc値の表示．\n",
    "    def __del__(self):\n",
    "        display.clear_output(wait = True)\n",
    "        print(\"val_acc: \",self.test_acc) \n",
    "        print('Time: ',time.time()-self.start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習を行う．課題3の MNIST とほぼ一緒．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc:  0.98\n",
      "Time:  109.78645086288452\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epoch=25\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1, min_lr=0.00001)\n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "show_graph=ShowGraph(num_epoch)\n",
    "show_graph.on_train_begin();\n",
    "\n",
    "def train():\n",
    "    loss=0\n",
    "    total=0\n",
    "    total0=0\n",
    "    correct=0\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        outputs = model(inputs.to(device))\n",
    "        labels=labels.to(device)\n",
    "        loss0= loss_fn(outputs, labels)\n",
    "        loss+= loss0.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        total0+=1\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss0.backward()\n",
    "        optimizer.step()\n",
    "    loss=loss/total0\n",
    "    acc=correct/total \n",
    "    return loss, acc\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "         vloss=0\n",
    "         total2=0\n",
    "         total20=0\n",
    "         correct2=0\n",
    "         for (inputs, labels) in testloader:\n",
    "             outputs = model(inputs.to(device))\n",
    "             labels=labels.to(device)\n",
    "             vloss += loss_fn(outputs, labels).item()\n",
    "             _, predicted = torch.max(outputs.data, 1)\n",
    "             total2 += labels.size(0)\n",
    "             total20+=1\n",
    "             correct2 += (predicted == labels).sum().item()\n",
    "         vloss=vloss/total20\n",
    "         vacc=correct2/total2\n",
    "    return vloss, vacc   \n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    l, a = train()   \n",
    "    lv, av = validate()\n",
    "    scheduler.step(lv) # val_lossが下がらなければlrを下げる\n",
    "    show_graph.on_epoch_end(epoch,l,a,lv,av)\n",
    "            \n",
    "del show_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 課題4\n",
    "\n",
    "以下の小問の(1)-(2)を解答すること．(3)は任意（できるだけやってみる方が望ましい．）．\n",
    "\n",
    "1. ResNet50, DenseNet, MobileNetV2で，3枚以上の画像について，それぞれ1000種類認識を行うこと．\n",
    "1. 上記のデータセットで，VGG16をfine-tuningして，画像分類を行うこと．データ拡張しない場合と，する場合を比較せよ．\n",
    "1. (2)と同様に, ResNet50, DenseNet など，別のネットワークで fine-tuningして，学習時間と精度を比較せよ．\n",
    "\n",
    "(2), (3)は以下のデータセットのどれかを利用すること．UEC-Food20 のみ20種類で，あとは10種類です．すべて1クラス100枚ずつ入っています．  \n",
    "（自分で用意可能な人は，自分で用意したものを利用してもよい．各カテゴリ100枚10クラス以上用意せよ．）\n",
    "\n",
    " * UEC-Food20 http://mm.cs.uec.ac.jp/uecfood20.zip\n",
    " * UEC-Food10 http://mm.cs.uec.ac.jp/uecfood10.zip (上記の10種類版．メモリが足りない場合にどうぞ．)\n",
    " * FlickrMaterialDatabase(FMD) http://mm.cs.uec.ac.jp/material10.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: setenv: not found\n",
      "--2021-04-19 11:15:09--  http://mm.cs.uec.ac.jp/uecfood10.zip\n",
      "Resolving proxy.uec.ac.jp (proxy.uec.ac.jp)... 130.153.8.24\n",
      "Connecting to proxy.uec.ac.jp (proxy.uec.ac.jp)|130.153.8.24|:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 32717628 (31M) [application/zip]\n",
      "Saving to: 'uecfood10.zip'\n",
      "\n",
      "uecfood10.zip       100%[===================>]  31.20M  56.5MB/s    in 0.6s    \n",
      "\n",
      "2021-04-19 11:15:11 (56.5 MB/s) - 'uecfood10.zip' saved [32717628/32717628]\n",
      "\n",
      "Archive:  uecfood10.zip\n",
      "   creating: uecfood10/\n",
      "   creating: uecfood10/sushi/\n",
      "  inflating: uecfood10/sushi/10577.jpg  \n",
      "  inflating: uecfood10/sushi/10655.jpg  \n",
      "  inflating: uecfood10/sushi/10717.jpg  \n",
      "  inflating: uecfood10/sushi/10852.jpg  \n",
      "  inflating: uecfood10/sushi/10853.jpg  \n",
      "  inflating: uecfood10/sushi/10854.jpg  \n",
      "  inflating: uecfood10/sushi/11102.jpg  \n",
      "  inflating: uecfood10/sushi/11361.jpg  \n",
      "  inflating: uecfood10/sushi/13681.jpg  \n",
      "  inflating: uecfood10/sushi/13682.jpg  \n",
      "  inflating: uecfood10/sushi/13719.jpg  \n",
      "  inflating: uecfood10/sushi/13753.jpg  \n",
      "  inflating: uecfood10/sushi/14070.jpg  \n",
      "  inflating: uecfood10/sushi/14359.jpg  \n",
      "  inflating: uecfood10/sushi/14384.jpg  \n",
      "  inflating: uecfood10/sushi/14529.jpg  \n",
      "  inflating: uecfood10/sushi/14539.jpg  \n",
      "  inflating: uecfood10/sushi/14569.jpg  \n",
      "  inflating: uecfood10/sushi/14570.jpg  \n",
      "  inflating: uecfood10/sushi/14571.jpg  \n",
      "  inflating: uecfood10/sushi/14572.jpg  \n",
      "  inflating: uecfood10/sushi/14579.jpg  \n",
      "  inflating: uecfood10/sushi/14586.jpg  \n",
      "  inflating: uecfood10/sushi/14657.jpg  \n",
      "  inflating: uecfood10/sushi/14672.jpg  \n",
      "  inflating: uecfood10/sushi/14677.jpg  \n",
      "  inflating: uecfood10/sushi/14720.jpg  \n",
      "  inflating: uecfood10/sushi/14765.jpg  \n",
      "  inflating: uecfood10/sushi/14840.jpg  \n",
      "  inflating: uecfood10/sushi/15049.jpg  \n",
      "  inflating: uecfood10/sushi/15073.jpg  \n",
      "  inflating: uecfood10/sushi/15116.jpg  \n",
      "  inflating: uecfood10/sushi/15121.jpg  \n",
      "  inflating: uecfood10/sushi/15172.jpg  \n",
      "  inflating: uecfood10/sushi/15307.jpg  \n",
      "  inflating: uecfood10/sushi/15460.jpg  \n",
      "  inflating: uecfood10/sushi/15782.jpg  \n",
      "  inflating: uecfood10/sushi/15918.jpg  \n",
      "  inflating: uecfood10/sushi/15919.jpg  \n",
      "  inflating: uecfood10/sushi/16104.jpg  \n",
      "  inflating: uecfood10/sushi/16118.jpg  \n",
      "  inflating: uecfood10/sushi/600.jpg  \n",
      "  inflating: uecfood10/sushi/601.jpg  \n",
      "  inflating: uecfood10/sushi/602.jpg  \n",
      "  inflating: uecfood10/sushi/603.jpg  \n",
      "  inflating: uecfood10/sushi/604.jpg  \n",
      "  inflating: uecfood10/sushi/605.jpg  \n",
      "  inflating: uecfood10/sushi/606.jpg  \n",
      "  inflating: uecfood10/sushi/607.jpg  \n",
      "  inflating: uecfood10/sushi/608.jpg  \n",
      "  inflating: uecfood10/sushi/609.jpg  \n",
      "  inflating: uecfood10/sushi/610.jpg  \n",
      "  inflating: uecfood10/sushi/611.jpg  \n",
      "  inflating: uecfood10/sushi/612.jpg  \n",
      "  inflating: uecfood10/sushi/613.jpg  \n",
      "  inflating: uecfood10/sushi/614.jpg  \n",
      "  inflating: uecfood10/sushi/615.jpg  \n",
      "  inflating: uecfood10/sushi/616.jpg  \n",
      "  inflating: uecfood10/sushi/617.jpg  \n",
      "  inflating: uecfood10/sushi/618.jpg  \n",
      "  inflating: uecfood10/sushi/619.jpg  \n",
      "  inflating: uecfood10/sushi/620.jpg  \n",
      "  inflating: uecfood10/sushi/621.jpg  \n",
      "  inflating: uecfood10/sushi/622.jpg  \n",
      "  inflating: uecfood10/sushi/623.jpg  \n",
      "  inflating: uecfood10/sushi/624.jpg  \n",
      "  inflating: uecfood10/sushi/625.jpg  \n",
      "  inflating: uecfood10/sushi/626.jpg  \n",
      "  inflating: uecfood10/sushi/627.jpg  \n",
      "  inflating: uecfood10/sushi/628.jpg  \n",
      "  inflating: uecfood10/sushi/629.jpg  \n",
      "  inflating: uecfood10/sushi/630.jpg  \n",
      "  inflating: uecfood10/sushi/631.jpg  \n",
      "  inflating: uecfood10/sushi/632.jpg  \n",
      "  inflating: uecfood10/sushi/633.jpg  \n",
      "  inflating: uecfood10/sushi/634.jpg  \n",
      "  inflating: uecfood10/sushi/635.jpg  \n",
      "  inflating: uecfood10/sushi/636.jpg  \n",
      "  inflating: uecfood10/sushi/637.jpg  \n",
      "  inflating: uecfood10/sushi/638.jpg  \n",
      "  inflating: uecfood10/sushi/639.jpg  \n",
      "  inflating: uecfood10/sushi/640.jpg  \n",
      "  inflating: uecfood10/sushi/641.jpg  \n",
      "  inflating: uecfood10/sushi/642.jpg  \n",
      "  inflating: uecfood10/sushi/643.jpg  \n",
      "  inflating: uecfood10/sushi/644.jpg  \n",
      "  inflating: uecfood10/sushi/645.jpg  \n",
      "  inflating: uecfood10/sushi/646.jpg  \n",
      "  inflating: uecfood10/sushi/647.jpg  \n",
      "  inflating: uecfood10/sushi/648.jpg  \n",
      "  inflating: uecfood10/sushi/649.jpg  \n",
      "  inflating: uecfood10/sushi/650.jpg  \n",
      "  inflating: uecfood10/sushi/651.jpg  \n",
      "  inflating: uecfood10/sushi/652.jpg  \n",
      "  inflating: uecfood10/sushi/653.jpg  \n",
      "  inflating: uecfood10/sushi/654.jpg  \n",
      "  inflating: uecfood10/sushi/655.jpg  \n",
      "  inflating: uecfood10/sushi/656.jpg  \n",
      "  inflating: uecfood10/sushi/657.jpg  \n",
      "  inflating: uecfood10/sushi/658.jpg  \n",
      "   creating: uecfood10/ramen/\n",
      "  inflating: uecfood10/ramen/10576.jpg  \n",
      "  inflating: uecfood10/ramen/10588.jpg  \n",
      "  inflating: uecfood10/ramen/10603.jpg  \n",
      "  inflating: uecfood10/ramen/10647.jpg  \n",
      "  inflating: uecfood10/ramen/10660.jpg  \n",
      "  inflating: uecfood10/ramen/10662.jpg  \n",
      "  inflating: uecfood10/ramen/10669.jpg  \n",
      "  inflating: uecfood10/ramen/10675.jpg  \n",
      "  inflating: uecfood10/ramen/10679.jpg  \n",
      "  inflating: uecfood10/ramen/10711.jpg  \n",
      "  inflating: uecfood10/ramen/10714.jpg  \n",
      "  inflating: uecfood10/ramen/10724.jpg  \n",
      "  inflating: uecfood10/ramen/10733.jpg  \n",
      "  inflating: uecfood10/ramen/10754.jpg  \n",
      "  inflating: uecfood10/ramen/10803.jpg  \n",
      "  inflating: uecfood10/ramen/10810.jpg  \n",
      "  inflating: uecfood10/ramen/10867.jpg  \n",
      "  inflating: uecfood10/ramen/10868.jpg  \n",
      "  inflating: uecfood10/ramen/10873.jpg  \n",
      "  inflating: uecfood10/ramen/10886.jpg  \n",
      "  inflating: uecfood10/ramen/10888.jpg  \n",
      "  inflating: uecfood10/ramen/10901.jpg  \n",
      "  inflating: uecfood10/ramen/10951.jpg  \n",
      "  inflating: uecfood10/ramen/10974.jpg  \n",
      "  inflating: uecfood10/ramen/11006.jpg  \n",
      "  inflating: uecfood10/ramen/11025.jpg  \n",
      "  inflating: uecfood10/ramen/11026.jpg  \n",
      "  inflating: uecfood10/ramen/11111.jpg  \n",
      "  inflating: uecfood10/ramen/11114.jpg  \n",
      "  inflating: uecfood10/ramen/11133.jpg  \n",
      "  inflating: uecfood10/ramen/11150.jpg  \n",
      "  inflating: uecfood10/ramen/11176.jpg  \n",
      "  inflating: uecfood10/ramen/11189.jpg  \n",
      "  inflating: uecfood10/ramen/11190.jpg  \n",
      "  inflating: uecfood10/ramen/11191.jpg  \n",
      "  inflating: uecfood10/ramen/11221.jpg  \n",
      "  inflating: uecfood10/ramen/11224.jpg  \n",
      "  inflating: uecfood10/ramen/11239.jpg  \n",
      "  inflating: uecfood10/ramen/11241.jpg  \n",
      "  inflating: uecfood10/ramen/11242.jpg  \n",
      "  inflating: uecfood10/ramen/11244.jpg  \n",
      "  inflating: uecfood10/ramen/11256.jpg  \n",
      "  inflating: uecfood10/ramen/11267.jpg  \n",
      "  inflating: uecfood10/ramen/11268.jpg  \n",
      "  inflating: uecfood10/ramen/11306.jpg  \n",
      "  inflating: uecfood10/ramen/11307.jpg  \n",
      "  inflating: uecfood10/ramen/11314.jpg  \n",
      "  inflating: uecfood10/ramen/11323.jpg  \n",
      "  inflating: uecfood10/ramen/11379.jpg  \n",
      "  inflating: uecfood10/ramen/11382.jpg  \n",
      "  inflating: uecfood10/ramen/11421.jpg  \n",
      "  inflating: uecfood10/ramen/11469.jpg  \n",
      "  inflating: uecfood10/ramen/11476.jpg  \n",
      "  inflating: uecfood10/ramen/11487.jpg  \n",
      "  inflating: uecfood10/ramen/11488.jpg  \n",
      "  inflating: uecfood10/ramen/11491.jpg  \n",
      "  inflating: uecfood10/ramen/11492.jpg  \n",
      "  inflating: uecfood10/ramen/11493.jpg  \n",
      "  inflating: uecfood10/ramen/11494.jpg  \n",
      "  inflating: uecfood10/ramen/11495.jpg  \n",
      "  inflating: uecfood10/ramen/11496.jpg  \n",
      "  inflating: uecfood10/ramen/11497.jpg  \n",
      "  inflating: uecfood10/ramen/11501.jpg  \n",
      "  inflating: uecfood10/ramen/11549.jpg  \n",
      "  inflating: uecfood10/ramen/11555.jpg  \n",
      "  inflating: uecfood10/ramen/11585.jpg  \n",
      "  inflating: uecfood10/ramen/11586.jpg  \n",
      "  inflating: uecfood10/ramen/11603.jpg  \n",
      "  inflating: uecfood10/ramen/11604.jpg  \n",
      "  inflating: uecfood10/ramen/11605.jpg  \n",
      "  inflating: uecfood10/ramen/11609.jpg  \n",
      "  inflating: uecfood10/ramen/11621.jpg  \n",
      "  inflating: uecfood10/ramen/11623.jpg  \n",
      "  inflating: uecfood10/ramen/11638.jpg  \n",
      "  inflating: uecfood10/ramen/11641.jpg  \n",
      "  inflating: uecfood10/ramen/11644.jpg  \n",
      "  inflating: uecfood10/ramen/11648.jpg  \n",
      "  inflating: uecfood10/ramen/11653.jpg  \n",
      "  inflating: uecfood10/ramen/11655.jpg  \n",
      "  inflating: uecfood10/ramen/11657.jpg  \n",
      "  inflating: uecfood10/ramen/11663.jpg  \n",
      "  inflating: uecfood10/ramen/11664.jpg  \n",
      "  inflating: uecfood10/ramen/11666.jpg  \n",
      "  inflating: uecfood10/ramen/11675.jpg  \n",
      "  inflating: uecfood10/ramen/11685.jpg  \n",
      "  inflating: uecfood10/ramen/11686.jpg  \n",
      "  inflating: uecfood10/ramen/11691.jpg  \n",
      "  inflating: uecfood10/ramen/11697.jpg  \n",
      "  inflating: uecfood10/ramen/12610.jpg  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  inflating: uecfood10/ramen/13037.jpg  \n",
      "  inflating: uecfood10/ramen/13602.jpg  \n",
      "  inflating: uecfood10/ramen/13605.jpg  \n",
      "  inflating: uecfood10/ramen/13608.jpg  \n",
      "  inflating: uecfood10/ramen/13610.jpg  \n",
      "  inflating: uecfood10/ramen/13620.jpg  \n",
      "  inflating: uecfood10/ramen/13623.jpg  \n",
      "  inflating: uecfood10/ramen/13624.jpg  \n",
      "  inflating: uecfood10/ramen/13627.jpg  \n",
      "  inflating: uecfood10/ramen/13629.jpg  \n",
      "  inflating: uecfood10/ramen/13631.jpg  \n",
      "   creating: uecfood10/okonomiyaki/\n",
      "  inflating: uecfood10/okonomiyaki/10793.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/10795.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/10818.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/10933.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/10934.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/11010.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/11011.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/11042.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/11043.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/11679.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/11680.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/13708.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/13979.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/14715.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/14750.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/14772.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/15359.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/15384.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/15434.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/15616.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/15710.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/15711.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/15751.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/15754.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/15755.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/15860.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/16013.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/16273.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2693.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2694.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2695.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2696.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2697.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2698.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2699.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2700.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2701.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2702.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2703.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2704.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2705.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2706.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2707.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2708.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2709.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2710.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2711.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2712.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2713.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2714.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2715.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2716.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2717.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2718.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2719.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2720.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2721.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2722.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2723.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2724.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2725.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2726.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2727.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2728.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2729.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2730.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2731.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2732.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2733.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2734.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2735.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2736.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2737.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2738.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2739.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2740.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2741.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2742.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2743.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2744.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2745.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2746.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2747.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2748.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2749.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2750.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2751.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2752.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2753.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2754.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2755.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2756.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2757.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2758.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2759.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2760.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2761.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2762.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2763.jpg  \n",
      "  inflating: uecfood10/okonomiyaki/2764.jpg  \n",
      "   creating: uecfood10/unaju/\n",
      "  inflating: uecfood10/unaju/100.jpg  \n",
      "  inflating: uecfood10/unaju/101.jpg  \n",
      "  inflating: uecfood10/unaju/102.jpg  \n",
      "  inflating: uecfood10/unaju/103.jpg  \n",
      "  inflating: uecfood10/unaju/104.jpg  \n",
      "  inflating: uecfood10/unaju/105.jpg  \n",
      "  inflating: uecfood10/unaju/10578.jpg  \n",
      "  inflating: uecfood10/unaju/106.jpg  \n",
      "  inflating: uecfood10/unaju/107.jpg  \n",
      "  inflating: uecfood10/unaju/10768.jpg  \n",
      "  inflating: uecfood10/unaju/108.jpg  \n",
      "  inflating: uecfood10/unaju/10897.jpg  \n",
      "  inflating: uecfood10/unaju/109.jpg  \n",
      "  inflating: uecfood10/unaju/10959.jpg  \n",
      "  inflating: uecfood10/unaju/110.jpg  \n",
      "  inflating: uecfood10/unaju/11078.jpg  \n",
      "  inflating: uecfood10/unaju/11079.jpg  \n",
      "  inflating: uecfood10/unaju/111.jpg  \n",
      "  inflating: uecfood10/unaju/112.jpg  \n",
      "  inflating: uecfood10/unaju/11258.jpg  \n",
      "  inflating: uecfood10/unaju/11259.jpg  \n",
      "  inflating: uecfood10/unaju/11298.jpg  \n",
      "  inflating: uecfood10/unaju/113.jpg  \n",
      "  inflating: uecfood10/unaju/114.jpg  \n",
      "  inflating: uecfood10/unaju/115.jpg  \n",
      "  inflating: uecfood10/unaju/116.jpg  \n",
      "  inflating: uecfood10/unaju/11629.jpg  \n",
      "  inflating: uecfood10/unaju/117.jpg  \n",
      "  inflating: uecfood10/unaju/118.jpg  \n",
      "  inflating: uecfood10/unaju/119.jpg  \n",
      "  inflating: uecfood10/unaju/120.jpg  \n",
      "  inflating: uecfood10/unaju/121.jpg  \n",
      "  inflating: uecfood10/unaju/122.jpg  \n",
      "  inflating: uecfood10/unaju/123.jpg  \n",
      "  inflating: uecfood10/unaju/124.jpg  \n",
      "  inflating: uecfood10/unaju/125.jpg  \n",
      "  inflating: uecfood10/unaju/126.jpg  \n",
      "  inflating: uecfood10/unaju/127.jpg  \n",
      "  inflating: uecfood10/unaju/128.jpg  \n",
      "  inflating: uecfood10/unaju/129.jpg  \n",
      "  inflating: uecfood10/unaju/130.jpg  \n",
      "  inflating: uecfood10/unaju/131.jpg  \n",
      "  inflating: uecfood10/unaju/132.jpg  \n",
      "  inflating: uecfood10/unaju/133.jpg  \n",
      "  inflating: uecfood10/unaju/134.jpg  \n",
      "  inflating: uecfood10/unaju/135.jpg  \n",
      "  inflating: uecfood10/unaju/136.jpg  \n",
      "  inflating: uecfood10/unaju/137.jpg  \n",
      "  inflating: uecfood10/unaju/13726.jpg  \n",
      "  inflating: uecfood10/unaju/13728.jpg  \n",
      "  inflating: uecfood10/unaju/138.jpg  \n",
      "  inflating: uecfood10/unaju/139.jpg  \n",
      "  inflating: uecfood10/unaju/140.jpg  \n",
      "  inflating: uecfood10/unaju/141.jpg  \n",
      "  inflating: uecfood10/unaju/142.jpg  \n",
      "  inflating: uecfood10/unaju/143.jpg  \n",
      "  inflating: uecfood10/unaju/144.jpg  \n",
      "  inflating: uecfood10/unaju/145.jpg  \n",
      "  inflating: uecfood10/unaju/146.jpg  \n",
      "  inflating: uecfood10/unaju/14632.jpg  \n",
      "  inflating: uecfood10/unaju/147.jpg  \n",
      "  inflating: uecfood10/unaju/148.jpg  \n",
      "  inflating: uecfood10/unaju/149.jpg  \n",
      "  inflating: uecfood10/unaju/150.jpg  \n",
      "  inflating: uecfood10/unaju/15060.jpg  \n",
      "  inflating: uecfood10/unaju/15093.jpg  \n",
      "  inflating: uecfood10/unaju/151.jpg  \n",
      "  inflating: uecfood10/unaju/15146.jpg  \n",
      "  inflating: uecfood10/unaju/152.jpg  \n",
      "  inflating: uecfood10/unaju/15245.jpg  \n",
      "  inflating: uecfood10/unaju/15280.jpg  \n",
      "  inflating: uecfood10/unaju/153.jpg  \n",
      "  inflating: uecfood10/unaju/15320.jpg  \n",
      "  inflating: uecfood10/unaju/15321.jpg  \n",
      "  inflating: uecfood10/unaju/154.jpg  \n",
      "  inflating: uecfood10/unaju/15444.jpg  \n",
      "  inflating: uecfood10/unaju/15481.jpg  \n",
      "  inflating: uecfood10/unaju/155.jpg  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  inflating: uecfood10/unaju/156.jpg  \n",
      "  inflating: uecfood10/unaju/15650.jpg  \n",
      "  inflating: uecfood10/unaju/15652.jpg  \n",
      "  inflating: uecfood10/unaju/157.jpg  \n",
      "  inflating: uecfood10/unaju/158.jpg  \n",
      "  inflating: uecfood10/unaju/15852.jpg  \n",
      "  inflating: uecfood10/unaju/159.jpg  \n",
      "  inflating: uecfood10/unaju/160.jpg  \n",
      "  inflating: uecfood10/unaju/161.jpg  \n",
      "  inflating: uecfood10/unaju/16109.jpg  \n",
      "  inflating: uecfood10/unaju/162.jpg  \n",
      "  inflating: uecfood10/unaju/163.jpg  \n",
      "  inflating: uecfood10/unaju/164.jpg  \n",
      "  inflating: uecfood10/unaju/165.jpg  \n",
      "  inflating: uecfood10/unaju/166.jpg  \n",
      "  inflating: uecfood10/unaju/167.jpg  \n",
      "  inflating: uecfood10/unaju/168.jpg  \n",
      "  inflating: uecfood10/unaju/169.jpg  \n",
      "  inflating: uecfood10/unaju/170.jpg  \n",
      "  inflating: uecfood10/unaju/171.jpg  \n",
      "  inflating: uecfood10/unaju/172.jpg  \n",
      "  inflating: uecfood10/unaju/173.jpg  \n",
      "   creating: uecfood10/katsudon/\n",
      "  inflating: uecfood10/katsudon/10708.jpg  \n",
      "  inflating: uecfood10/katsudon/10709.jpg  \n",
      "  inflating: uecfood10/katsudon/10843.jpg  \n",
      "  inflating: uecfood10/katsudon/10863.jpg  \n",
      "  inflating: uecfood10/katsudon/11222.jpg  \n",
      "  inflating: uecfood10/katsudon/11233.jpg  \n",
      "  inflating: uecfood10/katsudon/11247.jpg  \n",
      "  inflating: uecfood10/katsudon/11248.jpg  \n",
      "  inflating: uecfood10/katsudon/12178.jpg  \n",
      "  inflating: uecfood10/katsudon/13762.jpg  \n",
      "  inflating: uecfood10/katsudon/13765.jpg  \n",
      "  inflating: uecfood10/katsudon/13767.jpg  \n",
      "  inflating: uecfood10/katsudon/13771.jpg  \n",
      "  inflating: uecfood10/katsudon/14094.jpg  \n",
      "  inflating: uecfood10/katsudon/14739.jpg  \n",
      "  inflating: uecfood10/katsudon/14740.jpg  \n",
      "  inflating: uecfood10/katsudon/14810.jpg  \n",
      "  inflating: uecfood10/katsudon/14821.jpg  \n",
      "  inflating: uecfood10/katsudon/14826.jpg  \n",
      "  inflating: uecfood10/katsudon/14836.jpg  \n",
      "  inflating: uecfood10/katsudon/14838.jpg  \n",
      "  inflating: uecfood10/katsudon/14851.jpg  \n",
      "  inflating: uecfood10/katsudon/14852.jpg  \n",
      "  inflating: uecfood10/katsudon/14857.jpg  \n",
      "  inflating: uecfood10/katsudon/14858.jpg  \n",
      "  inflating: uecfood10/katsudon/14859.jpg  \n",
      "  inflating: uecfood10/katsudon/14860.jpg  \n",
      "  inflating: uecfood10/katsudon/14875.jpg  \n",
      "  inflating: uecfood10/katsudon/14879.jpg  \n",
      "  inflating: uecfood10/katsudon/14922.jpg  \n",
      "  inflating: uecfood10/katsudon/14972.jpg  \n",
      "  inflating: uecfood10/katsudon/15037.jpg  \n",
      "  inflating: uecfood10/katsudon/15144.jpg  \n",
      "  inflating: uecfood10/katsudon/15403.jpg  \n",
      "  inflating: uecfood10/katsudon/15442.jpg  \n",
      "  inflating: uecfood10/katsudon/15579.jpg  \n",
      "  inflating: uecfood10/katsudon/15648.jpg  \n",
      "  inflating: uecfood10/katsudon/15662.jpg  \n",
      "  inflating: uecfood10/katsudon/15720.jpg  \n",
      "  inflating: uecfood10/katsudon/15781.jpg  \n",
      "  inflating: uecfood10/katsudon/15809.jpg  \n",
      "  inflating: uecfood10/katsudon/15810.jpg  \n",
      "  inflating: uecfood10/katsudon/15943.jpg  \n",
      "  inflating: uecfood10/katsudon/16015.jpg  \n",
      "  inflating: uecfood10/katsudon/16112.jpg  \n",
      "  inflating: uecfood10/katsudon/16250.jpg  \n",
      "  inflating: uecfood10/katsudon/16267.jpg  \n",
      "  inflating: uecfood10/katsudon/16681.jpg  \n",
      "  inflating: uecfood10/katsudon/16707.jpg  \n",
      "  inflating: uecfood10/katsudon/400.jpg  \n",
      "  inflating: uecfood10/katsudon/401.jpg  \n",
      "  inflating: uecfood10/katsudon/402.jpg  \n",
      "  inflating: uecfood10/katsudon/403.jpg  \n",
      "  inflating: uecfood10/katsudon/404.jpg  \n",
      "  inflating: uecfood10/katsudon/405.jpg  \n",
      "  inflating: uecfood10/katsudon/406.jpg  \n",
      "  inflating: uecfood10/katsudon/407.jpg  \n",
      "  inflating: uecfood10/katsudon/408.jpg  \n",
      "  inflating: uecfood10/katsudon/409.jpg  \n",
      "  inflating: uecfood10/katsudon/410.jpg  \n",
      "  inflating: uecfood10/katsudon/411.jpg  \n",
      "  inflating: uecfood10/katsudon/412.jpg  \n",
      "  inflating: uecfood10/katsudon/413.jpg  \n",
      "  inflating: uecfood10/katsudon/414.jpg  \n",
      "  inflating: uecfood10/katsudon/415.jpg  \n",
      "  inflating: uecfood10/katsudon/416.jpg  \n",
      "  inflating: uecfood10/katsudon/417.jpg  \n",
      "  inflating: uecfood10/katsudon/418.jpg  \n",
      "  inflating: uecfood10/katsudon/419.jpg  \n",
      "  inflating: uecfood10/katsudon/420.jpg  \n",
      "  inflating: uecfood10/katsudon/421.jpg  \n",
      "  inflating: uecfood10/katsudon/422.jpg  \n",
      "  inflating: uecfood10/katsudon/423.jpg  \n",
      "  inflating: uecfood10/katsudon/424.jpg  \n",
      "  inflating: uecfood10/katsudon/425.jpg  \n",
      "  inflating: uecfood10/katsudon/426.jpg  \n",
      "  inflating: uecfood10/katsudon/427.jpg  \n",
      "  inflating: uecfood10/katsudon/428.jpg  \n",
      "  inflating: uecfood10/katsudon/429.jpg  \n",
      "  inflating: uecfood10/katsudon/430.jpg  \n",
      "  inflating: uecfood10/katsudon/431.jpg  \n",
      "  inflating: uecfood10/katsudon/432.jpg  \n",
      "  inflating: uecfood10/katsudon/433.jpg  \n",
      "  inflating: uecfood10/katsudon/434.jpg  \n",
      "  inflating: uecfood10/katsudon/435.jpg  \n",
      "  inflating: uecfood10/katsudon/436.jpg  \n",
      "  inflating: uecfood10/katsudon/437.jpg  \n",
      "  inflating: uecfood10/katsudon/438.jpg  \n",
      "  inflating: uecfood10/katsudon/439.jpg  \n",
      "  inflating: uecfood10/katsudon/440.jpg  \n",
      "  inflating: uecfood10/katsudon/441.jpg  \n",
      "  inflating: uecfood10/katsudon/442.jpg  \n",
      "  inflating: uecfood10/katsudon/443.jpg  \n",
      "  inflating: uecfood10/katsudon/444.jpg  \n",
      "  inflating: uecfood10/katsudon/445.jpg  \n",
      "  inflating: uecfood10/katsudon/446.jpg  \n",
      "  inflating: uecfood10/katsudon/447.jpg  \n",
      "  inflating: uecfood10/katsudon/448.jpg  \n",
      "  inflating: uecfood10/katsudon/449.jpg  \n",
      "  inflating: uecfood10/katsudon/450.jpg  \n",
      "   creating: uecfood10/hamburger/\n",
      "  inflating: uecfood10/hamburger/10593.jpg  \n",
      "  inflating: uecfood10/hamburger/10657.jpg  \n",
      "  inflating: uecfood10/hamburger/10919.jpg  \n",
      "  inflating: uecfood10/hamburger/10950.jpg  \n",
      "  inflating: uecfood10/hamburger/11049.jpg  \n",
      "  inflating: uecfood10/hamburger/11050.jpg  \n",
      "  inflating: uecfood10/hamburger/11054.jpg  \n",
      "  inflating: uecfood10/hamburger/11055.jpg  \n",
      "  inflating: uecfood10/hamburger/11082.jpg  \n",
      "  inflating: uecfood10/hamburger/11083.jpg  \n",
      "  inflating: uecfood10/hamburger/11089.jpg  \n",
      "  inflating: uecfood10/hamburger/11090.jpg  \n",
      "  inflating: uecfood10/hamburger/11091.jpg  \n",
      "  inflating: uecfood10/hamburger/11117.jpg  \n",
      "  inflating: uecfood10/hamburger/11118.jpg  \n",
      "  inflating: uecfood10/hamburger/11179.jpg  \n",
      "  inflating: uecfood10/hamburger/11249.jpg  \n",
      "  inflating: uecfood10/hamburger/11260.jpg  \n",
      "  inflating: uecfood10/hamburger/11427.jpg  \n",
      "  inflating: uecfood10/hamburger/11443.jpg  \n",
      "  inflating: uecfood10/hamburger/11561.jpg  \n",
      "  inflating: uecfood10/hamburger/11687.jpg  \n",
      "  inflating: uecfood10/hamburger/13760.jpg  \n",
      "  inflating: uecfood10/hamburger/13761.jpg  \n",
      "  inflating: uecfood10/hamburger/13766.jpg  \n",
      "  inflating: uecfood10/hamburger/13783.jpg  \n",
      "  inflating: uecfood10/hamburger/13785.jpg  \n",
      "  inflating: uecfood10/hamburger/14054.jpg  \n",
      "  inflating: uecfood10/hamburger/14059.jpg  \n",
      "  inflating: uecfood10/hamburger/14073.jpg  \n",
      "  inflating: uecfood10/hamburger/14275.jpg  \n",
      "  inflating: uecfood10/hamburger/14277.jpg  \n",
      "  inflating: uecfood10/hamburger/14314.jpg  \n",
      "  inflating: uecfood10/hamburger/14331.jpg  \n",
      "  inflating: uecfood10/hamburger/14381.jpg  \n",
      "  inflating: uecfood10/hamburger/14385.jpg  \n",
      "  inflating: uecfood10/hamburger/14466.jpg  \n",
      "  inflating: uecfood10/hamburger/14499.jpg  \n",
      "  inflating: uecfood10/hamburger/14575.jpg  \n",
      "  inflating: uecfood10/hamburger/14753.jpg  \n",
      "  inflating: uecfood10/hamburger/14757.jpg  \n",
      "  inflating: uecfood10/hamburger/14771.jpg  \n",
      "  inflating: uecfood10/hamburger/14897.jpg  \n",
      "  inflating: uecfood10/hamburger/14977.jpg  \n",
      "  inflating: uecfood10/hamburger/14978.jpg  \n",
      "  inflating: uecfood10/hamburger/14980.jpg  \n",
      "  inflating: uecfood10/hamburger/14981.jpg  \n",
      "  inflating: uecfood10/hamburger/14982.jpg  \n",
      "  inflating: uecfood10/hamburger/14984.jpg  \n",
      "  inflating: uecfood10/hamburger/14986.jpg  \n",
      "  inflating: uecfood10/hamburger/15021.jpg  \n",
      "  inflating: uecfood10/hamburger/15045.jpg  \n",
      "  inflating: uecfood10/hamburger/15120.jpg  \n",
      "  inflating: uecfood10/hamburger/15137.jpg  \n",
      "  inflating: uecfood10/hamburger/15139.jpg  \n",
      "  inflating: uecfood10/hamburger/15143.jpg  \n",
      "  inflating: uecfood10/hamburger/15206.jpg  \n",
      "  inflating: uecfood10/hamburger/15260.jpg  \n",
      "  inflating: uecfood10/hamburger/15283.jpg  \n",
      "  inflating: uecfood10/hamburger/15306.jpg  \n",
      "  inflating: uecfood10/hamburger/15331.jpg  \n",
      "  inflating: uecfood10/hamburger/15332.jpg  \n",
      "  inflating: uecfood10/hamburger/15333.jpg  \n",
      "  inflating: uecfood10/hamburger/15345.jpg  \n",
      "  inflating: uecfood10/hamburger/15350.jpg  \n",
      "  inflating: uecfood10/hamburger/15378.jpg  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  inflating: uecfood10/hamburger/15379.jpg  \n",
      "  inflating: uecfood10/hamburger/15394.jpg  \n",
      "  inflating: uecfood10/hamburger/15405.jpg  \n",
      "  inflating: uecfood10/hamburger/15406.jpg  \n",
      "  inflating: uecfood10/hamburger/15463.jpg  \n",
      "  inflating: uecfood10/hamburger/15482.jpg  \n",
      "  inflating: uecfood10/hamburger/15513.jpg  \n",
      "  inflating: uecfood10/hamburger/15522.jpg  \n",
      "  inflating: uecfood10/hamburger/15532.jpg  \n",
      "  inflating: uecfood10/hamburger/15533.jpg  \n",
      "  inflating: uecfood10/hamburger/15561.jpg  \n",
      "  inflating: uecfood10/hamburger/15582.jpg  \n",
      "  inflating: uecfood10/hamburger/15590.jpg  \n",
      "  inflating: uecfood10/hamburger/15594.jpg  \n",
      "  inflating: uecfood10/hamburger/15606.jpg  \n",
      "  inflating: uecfood10/hamburger/15624.jpg  \n",
      "  inflating: uecfood10/hamburger/15681.jpg  \n",
      "  inflating: uecfood10/hamburger/15684.jpg  \n",
      "  inflating: uecfood10/hamburger/15696.jpg  \n",
      "  inflating: uecfood10/hamburger/15703.jpg  \n",
      "  inflating: uecfood10/hamburger/15714.jpg  \n",
      "  inflating: uecfood10/hamburger/15716.jpg  \n",
      "  inflating: uecfood10/hamburger/15743.jpg  \n",
      "  inflating: uecfood10/hamburger/15783.jpg  \n",
      "  inflating: uecfood10/hamburger/15827.jpg  \n",
      "  inflating: uecfood10/hamburger/15903.jpg  \n",
      "  inflating: uecfood10/hamburger/1592.jpg  \n",
      "  inflating: uecfood10/hamburger/15920.jpg  \n",
      "  inflating: uecfood10/hamburger/1593.jpg  \n",
      "  inflating: uecfood10/hamburger/15934.jpg  \n",
      "  inflating: uecfood10/hamburger/15935.jpg  \n",
      "  inflating: uecfood10/hamburger/1594.jpg  \n",
      "  inflating: uecfood10/hamburger/15944.jpg  \n",
      "  inflating: uecfood10/hamburger/1595.jpg  \n",
      "   creating: uecfood10/fried-rice/\n",
      "  inflating: uecfood10/fried-rice/10582.jpg  \n",
      "  inflating: uecfood10/fried-rice/10678.jpg  \n",
      "  inflating: uecfood10/fried-rice/10710.jpg  \n",
      "  inflating: uecfood10/fried-rice/10784.jpg  \n",
      "  inflating: uecfood10/fried-rice/10786.jpg  \n",
      "  inflating: uecfood10/fried-rice/10821.jpg  \n",
      "  inflating: uecfood10/fried-rice/11000.jpg  \n",
      "  inflating: uecfood10/fried-rice/11044.jpg  \n",
      "  inflating: uecfood10/fried-rice/11045.jpg  \n",
      "  inflating: uecfood10/fried-rice/11065.jpg  \n",
      "  inflating: uecfood10/fried-rice/11097.jpg  \n",
      "  inflating: uecfood10/fried-rice/11113.jpg  \n",
      "  inflating: uecfood10/fried-rice/11143.jpg  \n",
      "  inflating: uecfood10/fried-rice/11145.jpg  \n",
      "  inflating: uecfood10/fried-rice/11227.jpg  \n",
      "  inflating: uecfood10/fried-rice/11238.jpg  \n",
      "  inflating: uecfood10/fried-rice/11348.jpg  \n",
      "  inflating: uecfood10/fried-rice/11426.jpg  \n",
      "  inflating: uecfood10/fried-rice/11435.jpg  \n",
      "  inflating: uecfood10/fried-rice/11454.jpg  \n",
      "  inflating: uecfood10/fried-rice/11507.jpg  \n",
      "  inflating: uecfood10/fried-rice/11596.jpg  \n",
      "  inflating: uecfood10/fried-rice/11603.jpg  \n",
      "  inflating: uecfood10/fried-rice/13630.jpg  \n",
      "  inflating: uecfood10/fried-rice/13697.jpg  \n",
      "  inflating: uecfood10/fried-rice/13712.jpg  \n",
      "  inflating: uecfood10/fried-rice/13713.jpg  \n",
      "  inflating: uecfood10/fried-rice/13720.jpg  \n",
      "  inflating: uecfood10/fried-rice/13743.jpg  \n",
      "  inflating: uecfood10/fried-rice/13816.jpg  \n",
      "  inflating: uecfood10/fried-rice/13993.jpg  \n",
      "  inflating: uecfood10/fried-rice/13997.jpg  \n",
      "  inflating: uecfood10/fried-rice/14082.jpg  \n",
      "  inflating: uecfood10/fried-rice/14226.jpg  \n",
      "  inflating: uecfood10/fried-rice/14234.jpg  \n",
      "  inflating: uecfood10/fried-rice/14593.jpg  \n",
      "  inflating: uecfood10/fried-rice/14650.jpg  \n",
      "  inflating: uecfood10/fried-rice/14725.jpg  \n",
      "  inflating: uecfood10/fried-rice/14861.jpg  \n",
      "  inflating: uecfood10/fried-rice/14898.jpg  \n",
      "  inflating: uecfood10/fried-rice/14966.jpg  \n",
      "  inflating: uecfood10/fried-rice/15425.jpg  \n",
      "  inflating: uecfood10/fried-rice/15510.jpg  \n",
      "  inflating: uecfood10/fried-rice/15518.jpg  \n",
      "  inflating: uecfood10/fried-rice/15536.jpg  \n",
      "  inflating: uecfood10/fried-rice/15601.jpg  \n",
      "  inflating: uecfood10/fried-rice/15692.jpg  \n",
      "  inflating: uecfood10/fried-rice/15847.jpg  \n",
      "  inflating: uecfood10/fried-rice/15865.jpg  \n",
      "  inflating: uecfood10/fried-rice/15878.jpg  \n",
      "  inflating: uecfood10/fried-rice/16387.jpg  \n",
      "  inflating: uecfood10/fried-rice/16617.jpg  \n",
      "  inflating: uecfood10/fried-rice/16676.jpg  \n",
      "  inflating: uecfood10/fried-rice/16693.jpg  \n",
      "  inflating: uecfood10/fried-rice/2460.jpg  \n",
      "  inflating: uecfood10/fried-rice/5183.jpg  \n",
      "  inflating: uecfood10/fried-rice/7186.jpg  \n",
      "  inflating: uecfood10/fried-rice/800.jpg  \n",
      "  inflating: uecfood10/fried-rice/801.jpg  \n",
      "  inflating: uecfood10/fried-rice/802.jpg  \n",
      "  inflating: uecfood10/fried-rice/803.jpg  \n",
      "  inflating: uecfood10/fried-rice/804.jpg  \n",
      "  inflating: uecfood10/fried-rice/805.jpg  \n",
      "  inflating: uecfood10/fried-rice/806.jpg  \n",
      "  inflating: uecfood10/fried-rice/807.jpg  \n",
      "  inflating: uecfood10/fried-rice/808.jpg  \n",
      "  inflating: uecfood10/fried-rice/809.jpg  \n",
      "  inflating: uecfood10/fried-rice/810.jpg  \n",
      "  inflating: uecfood10/fried-rice/811.jpg  \n",
      "  inflating: uecfood10/fried-rice/812.jpg  \n",
      "  inflating: uecfood10/fried-rice/813.jpg  \n",
      "  inflating: uecfood10/fried-rice/814.jpg  \n",
      "  inflating: uecfood10/fried-rice/815.jpg  \n",
      "  inflating: uecfood10/fried-rice/816.jpg  \n",
      "  inflating: uecfood10/fried-rice/817.jpg  \n",
      "  inflating: uecfood10/fried-rice/818.jpg  \n",
      "  inflating: uecfood10/fried-rice/819.jpg  \n",
      "  inflating: uecfood10/fried-rice/820.jpg  \n",
      "  inflating: uecfood10/fried-rice/821.jpg  \n",
      "  inflating: uecfood10/fried-rice/822.jpg  \n",
      "  inflating: uecfood10/fried-rice/823.jpg  \n",
      "  inflating: uecfood10/fried-rice/824.jpg  \n",
      "  inflating: uecfood10/fried-rice/825.jpg  \n",
      "  inflating: uecfood10/fried-rice/826.jpg  \n",
      "  inflating: uecfood10/fried-rice/827.jpg  \n",
      "  inflating: uecfood10/fried-rice/828.jpg  \n",
      "  inflating: uecfood10/fried-rice/829.jpg  \n",
      "  inflating: uecfood10/fried-rice/830.jpg  \n",
      "  inflating: uecfood10/fried-rice/831.jpg  \n",
      "  inflating: uecfood10/fried-rice/832.jpg  \n",
      "  inflating: uecfood10/fried-rice/833.jpg  \n",
      "  inflating: uecfood10/fried-rice/834.jpg  \n",
      "  inflating: uecfood10/fried-rice/835.jpg  \n",
      "  inflating: uecfood10/fried-rice/836.jpg  \n",
      "  inflating: uecfood10/fried-rice/837.jpg  \n",
      "  inflating: uecfood10/fried-rice/838.jpg  \n",
      "  inflating: uecfood10/fried-rice/839.jpg  \n",
      "  inflating: uecfood10/fried-rice/840.jpg  \n",
      "  inflating: uecfood10/fried-rice/841.jpg  \n",
      "  inflating: uecfood10/fried-rice/842.jpg  \n",
      "   creating: uecfood10/sandwich/\n",
      "  inflating: uecfood10/sandwich/10840.jpg  \n",
      "  inflating: uecfood10/sandwich/11008.jpg  \n",
      "  inflating: uecfood10/sandwich/13611.jpg  \n",
      "  inflating: uecfood10/sandwich/13622.jpg  \n",
      "  inflating: uecfood10/sandwich/13706.jpg  \n",
      "  inflating: uecfood10/sandwich/13707.jpg  \n",
      "  inflating: uecfood10/sandwich/13710.jpg  \n",
      "  inflating: uecfood10/sandwich/13718.jpg  \n",
      "  inflating: uecfood10/sandwich/13970.jpg  \n",
      "  inflating: uecfood10/sandwich/14014.jpg  \n",
      "  inflating: uecfood10/sandwich/14019.jpg  \n",
      "  inflating: uecfood10/sandwich/14020.jpg  \n",
      "  inflating: uecfood10/sandwich/14024.jpg  \n",
      "  inflating: uecfood10/sandwich/14028.jpg  \n",
      "  inflating: uecfood10/sandwich/14034.jpg  \n",
      "  inflating: uecfood10/sandwich/14037.jpg  \n",
      "  inflating: uecfood10/sandwich/14040.jpg  \n",
      "  inflating: uecfood10/sandwich/14045.jpg  \n",
      "  inflating: uecfood10/sandwich/14047.jpg  \n",
      "  inflating: uecfood10/sandwich/14049.jpg  \n",
      "  inflating: uecfood10/sandwich/14053.jpg  \n",
      "  inflating: uecfood10/sandwich/14066.jpg  \n",
      "  inflating: uecfood10/sandwich/14067.jpg  \n",
      "  inflating: uecfood10/sandwich/14075.jpg  \n",
      "  inflating: uecfood10/sandwich/14088.jpg  \n",
      "  inflating: uecfood10/sandwich/14101.jpg  \n",
      "  inflating: uecfood10/sandwich/14306.jpg  \n",
      "  inflating: uecfood10/sandwich/14325.jpg  \n",
      "  inflating: uecfood10/sandwich/14343.jpg  \n",
      "  inflating: uecfood10/sandwich/14414.jpg  \n",
      "  inflating: uecfood10/sandwich/14437.jpg  \n",
      "  inflating: uecfood10/sandwich/14440.jpg  \n",
      "  inflating: uecfood10/sandwich/14442.jpg  \n",
      "  inflating: uecfood10/sandwich/14444.jpg  \n",
      "  inflating: uecfood10/sandwich/14450.jpg  \n",
      "  inflating: uecfood10/sandwich/14452.jpg  \n",
      "  inflating: uecfood10/sandwich/14455.jpg  \n",
      "  inflating: uecfood10/sandwich/14464.jpg  \n",
      "  inflating: uecfood10/sandwich/14468.jpg  \n",
      "  inflating: uecfood10/sandwich/14475.jpg  \n",
      "  inflating: uecfood10/sandwich/14478.jpg  \n",
      "  inflating: uecfood10/sandwich/14479.jpg  \n",
      "  inflating: uecfood10/sandwich/14484.jpg  \n",
      "  inflating: uecfood10/sandwich/14487.jpg  \n",
      "  inflating: uecfood10/sandwich/14502.jpg  \n",
      "  inflating: uecfood10/sandwich/14564.jpg  \n",
      "  inflating: uecfood10/sandwich/14618.jpg  \n",
      "  inflating: uecfood10/sandwich/14635.jpg  \n",
      "  inflating: uecfood10/sandwich/14637.jpg  \n",
      "  inflating: uecfood10/sandwich/14654.jpg  \n",
      "  inflating: uecfood10/sandwich/14660.jpg  \n",
      "  inflating: uecfood10/sandwich/14674.jpg  \n",
      "  inflating: uecfood10/sandwich/14688.jpg  \n",
      "  inflating: uecfood10/sandwich/14693.jpg  \n",
      "  inflating: uecfood10/sandwich/14721.jpg  \n",
      "  inflating: uecfood10/sandwich/14735.jpg  \n",
      "  inflating: uecfood10/sandwich/15255.jpg  \n",
      "  inflating: uecfood10/sandwich/15262.jpg  \n",
      "  inflating: uecfood10/sandwich/1537.jpg  \n",
      "  inflating: uecfood10/sandwich/15496.jpg  \n",
      "  inflating: uecfood10/sandwich/1792.jpg  \n",
      "  inflating: uecfood10/sandwich/1793.jpg  \n",
      "  inflating: uecfood10/sandwich/1794.jpg  \n",
      "  inflating: uecfood10/sandwich/1795.jpg  \n",
      "  inflating: uecfood10/sandwich/1796.jpg  \n",
      "  inflating: uecfood10/sandwich/1797.jpg  \n",
      "  inflating: uecfood10/sandwich/1798.jpg  \n",
      "  inflating: uecfood10/sandwich/1799.jpg  \n",
      "  inflating: uecfood10/sandwich/1800.jpg  \n",
      "  inflating: uecfood10/sandwich/1801.jpg  \n",
      "  inflating: uecfood10/sandwich/1802.jpg  \n",
      "  inflating: uecfood10/sandwich/1803.jpg  \n",
      "  inflating: uecfood10/sandwich/1804.jpg  \n",
      "  inflating: uecfood10/sandwich/1805.jpg  \n",
      "  inflating: uecfood10/sandwich/1806.jpg  \n",
      "  inflating: uecfood10/sandwich/1807.jpg  \n",
      "  inflating: uecfood10/sandwich/1808.jpg  \n",
      "  inflating: uecfood10/sandwich/1809.jpg  \n",
      "  inflating: uecfood10/sandwich/1810.jpg  \n",
      "  inflating: uecfood10/sandwich/1811.jpg  \n",
      "  inflating: uecfood10/sandwich/1812.jpg  \n",
      "  inflating: uecfood10/sandwich/1813.jpg  \n",
      "  inflating: uecfood10/sandwich/1814.jpg  \n",
      "  inflating: uecfood10/sandwich/1815.jpg  \n",
      "  inflating: uecfood10/sandwich/1816.jpg  \n",
      "  inflating: uecfood10/sandwich/1817.jpg  \n",
      "  inflating: uecfood10/sandwich/1818.jpg  \n",
      "  inflating: uecfood10/sandwich/1819.jpg  \n",
      "  inflating: uecfood10/sandwich/1820.jpg  \n",
      "  inflating: uecfood10/sandwich/1821.jpg  \n",
      "  inflating: uecfood10/sandwich/1822.jpg  \n",
      "  inflating: uecfood10/sandwich/1823.jpg  \n",
      "  inflating: uecfood10/sandwich/1824.jpg  \n",
      "  inflating: uecfood10/sandwich/1825.jpg  \n",
      "  inflating: uecfood10/sandwich/1826.jpg  \n",
      "  inflating: uecfood10/sandwich/1827.jpg  \n",
      "  inflating: uecfood10/sandwich/1828.jpg  \n",
      "  inflating: uecfood10/sandwich/1829.jpg  \n",
      "  inflating: uecfood10/sandwich/1830.jpg  \n",
      "  inflating: uecfood10/sandwich/1831.jpg  \n",
      "   creating: uecfood10/beef-curry/\n",
      "  inflating: uecfood10/beef-curry/10575.jpg  \n",
      "  inflating: uecfood10/beef-curry/10751.jpg  \n",
      "  inflating: uecfood10/beef-curry/10763.jpg  \n",
      "  inflating: uecfood10/beef-curry/10804.jpg  \n",
      "  inflating: uecfood10/beef-curry/10824.jpg  \n",
      "  inflating: uecfood10/beef-curry/10827.jpg  \n",
      "  inflating: uecfood10/beef-curry/10839.jpg  \n",
      "  inflating: uecfood10/beef-curry/10856.jpg  \n",
      "  inflating: uecfood10/beef-curry/10857.jpg  \n",
      "  inflating: uecfood10/beef-curry/10898.jpg  \n",
      "  inflating: uecfood10/beef-curry/10952.jpg  \n",
      "  inflating: uecfood10/beef-curry/10957.jpg  \n",
      "  inflating: uecfood10/beef-curry/10978.jpg  \n",
      "  inflating: uecfood10/beef-curry/10998.jpg  \n",
      "  inflating: uecfood10/beef-curry/11060.jpg  \n",
      "  inflating: uecfood10/beef-curry/11068.jpg  \n",
      "  inflating: uecfood10/beef-curry/11131.jpg  \n",
      "  inflating: uecfood10/beef-curry/11171.jpg  \n",
      "  inflating: uecfood10/beef-curry/11228.jpg  \n",
      "  inflating: uecfood10/beef-curry/11234.jpg  \n",
      "  inflating: uecfood10/beef-curry/11383.jpg  \n",
      "  inflating: uecfood10/beef-curry/11411.jpg  \n",
      "  inflating: uecfood10/beef-curry/11502.jpg  \n",
      "  inflating: uecfood10/beef-curry/11545.jpg  \n",
      "  inflating: uecfood10/beef-curry/11582.jpg  \n",
      "  inflating: uecfood10/beef-curry/11617.jpg  \n",
      "  inflating: uecfood10/beef-curry/11667.jpg  \n",
      "  inflating: uecfood10/beef-curry/11668.jpg  \n",
      "  inflating: uecfood10/beef-curry/11692.jpg  \n",
      "  inflating: uecfood10/beef-curry/11863.jpg  \n",
      "  inflating: uecfood10/beef-curry/11893.jpg  \n",
      "  inflating: uecfood10/beef-curry/12871.jpg  \n",
      "  inflating: uecfood10/beef-curry/12872.jpg  \n",
      "  inflating: uecfood10/beef-curry/12878.jpg  \n",
      "  inflating: uecfood10/beef-curry/12879.jpg  \n",
      "  inflating: uecfood10/beef-curry/12880.jpg  \n",
      "  inflating: uecfood10/beef-curry/12881.jpg  \n",
      "  inflating: uecfood10/beef-curry/12883.jpg  \n",
      "  inflating: uecfood10/beef-curry/12886.jpg  \n",
      "  inflating: uecfood10/beef-curry/12888.jpg  \n",
      "  inflating: uecfood10/beef-curry/12889.jpg  \n",
      "  inflating: uecfood10/beef-curry/12890.jpg  \n",
      "  inflating: uecfood10/beef-curry/12893.jpg  \n",
      "  inflating: uecfood10/beef-curry/12896.jpg  \n",
      "  inflating: uecfood10/beef-curry/12897.jpg  \n",
      "  inflating: uecfood10/beef-curry/12898.jpg  \n",
      "  inflating: uecfood10/beef-curry/12899.jpg  \n",
      "  inflating: uecfood10/beef-curry/12900.jpg  \n",
      "  inflating: uecfood10/beef-curry/12901.jpg  \n",
      "  inflating: uecfood10/beef-curry/12904.jpg  \n",
      "  inflating: uecfood10/beef-curry/12905.jpg  \n",
      "  inflating: uecfood10/beef-curry/12909.jpg  \n",
      "  inflating: uecfood10/beef-curry/12912.jpg  \n",
      "  inflating: uecfood10/beef-curry/12913.jpg  \n",
      "  inflating: uecfood10/beef-curry/12923.jpg  \n",
      "  inflating: uecfood10/beef-curry/12928.jpg  \n",
      "  inflating: uecfood10/beef-curry/12929.jpg  \n",
      "  inflating: uecfood10/beef-curry/13020.jpg  \n",
      "  inflating: uecfood10/beef-curry/13672.jpg  \n",
      "  inflating: uecfood10/beef-curry/13699.jpg  \n",
      "  inflating: uecfood10/beef-curry/13709.jpg  \n",
      "  inflating: uecfood10/beef-curry/13711.jpg  \n",
      "  inflating: uecfood10/beef-curry/13722.jpg  \n",
      "  inflating: uecfood10/beef-curry/13730.jpg  \n",
      "  inflating: uecfood10/beef-curry/13737.jpg  \n",
      "  inflating: uecfood10/beef-curry/13756.jpg  \n",
      "  inflating: uecfood10/beef-curry/13773.jpg  \n",
      "  inflating: uecfood10/beef-curry/13786.jpg  \n",
      "  inflating: uecfood10/beef-curry/13794.jpg  \n",
      "  inflating: uecfood10/beef-curry/13860.jpg  \n",
      "  inflating: uecfood10/beef-curry/13892.jpg  \n",
      "  inflating: uecfood10/beef-curry/13934.jpg  \n",
      "  inflating: uecfood10/beef-curry/13964.jpg  \n",
      "  inflating: uecfood10/beef-curry/13976.jpg  \n",
      "  inflating: uecfood10/beef-curry/13980.jpg  \n",
      "  inflating: uecfood10/beef-curry/14027.jpg  \n",
      "  inflating: uecfood10/beef-curry/14046.jpg  \n",
      "  inflating: uecfood10/beef-curry/14052.jpg  \n",
      "  inflating: uecfood10/beef-curry/14063.jpg  \n",
      "  inflating: uecfood10/beef-curry/14078.jpg  \n",
      "  inflating: uecfood10/beef-curry/14081.jpg  \n",
      "  inflating: uecfood10/beef-curry/14087.jpg  \n",
      "  inflating: uecfood10/beef-curry/14220.jpg  \n",
      "  inflating: uecfood10/beef-curry/14427.jpg  \n",
      "  inflating: uecfood10/beef-curry/14488.jpg  \n",
      "  inflating: uecfood10/beef-curry/14554.jpg  \n",
      "  inflating: uecfood10/beef-curry/14567.jpg  \n",
      "  inflating: uecfood10/beef-curry/14628.jpg  \n",
      "  inflating: uecfood10/beef-curry/14676.jpg  \n",
      "  inflating: uecfood10/beef-curry/14684.jpg  \n",
      "  inflating: uecfood10/beef-curry/14686.jpg  \n",
      "  inflating: uecfood10/beef-curry/14730.jpg  \n",
      "  inflating: uecfood10/beef-curry/14748.jpg  \n",
      "  inflating: uecfood10/beef-curry/15040.jpg  \n",
      "  inflating: uecfood10/beef-curry/15044.jpg  \n",
      "  inflating: uecfood10/beef-curry/15124.jpg  \n",
      "  inflating: uecfood10/beef-curry/15129.jpg  \n",
      "  inflating: uecfood10/beef-curry/15163.jpg  \n",
      "  inflating: uecfood10/beef-curry/15168.jpg  \n",
      "  inflating: uecfood10/beef-curry/15203.jpg  \n",
      "   creating: uecfood10/takoyaki/\n",
      "  inflating: uecfood10/takoyaki/13616.jpg  \n",
      "  inflating: uecfood10/takoyaki/14085.jpg  \n",
      "  inflating: uecfood10/takoyaki/14542.jpg  \n",
      "  inflating: uecfood10/takoyaki/14543.jpg  \n",
      "  inflating: uecfood10/takoyaki/14587.jpg  \n",
      "  inflating: uecfood10/takoyaki/14648.jpg  \n",
      "  inflating: uecfood10/takoyaki/15249.jpg  \n",
      "  inflating: uecfood10/takoyaki/15252.jpg  \n",
      "  inflating: uecfood10/takoyaki/15253.jpg  \n",
      "  inflating: uecfood10/takoyaki/15254.jpg  \n",
      "  inflating: uecfood10/takoyaki/15338.jpg  \n",
      "  inflating: uecfood10/takoyaki/15575.jpg  \n",
      "  inflating: uecfood10/takoyaki/15580.jpg  \n",
      "  inflating: uecfood10/takoyaki/15745.jpg  \n",
      "  inflating: uecfood10/takoyaki/15753.jpg  \n",
      "  inflating: uecfood10/takoyaki/15775.jpg  \n",
      "  inflating: uecfood10/takoyaki/15811.jpg  \n",
      "  inflating: uecfood10/takoyaki/15877.jpg  \n",
      "  inflating: uecfood10/takoyaki/16345.jpg  \n",
      "  inflating: uecfood10/takoyaki/16356.jpg  \n",
      "  inflating: uecfood10/takoyaki/16661.jpg  \n",
      "  inflating: uecfood10/takoyaki/2793.jpg  \n",
      "  inflating: uecfood10/takoyaki/2794.jpg  \n",
      "  inflating: uecfood10/takoyaki/2795.jpg  \n",
      "  inflating: uecfood10/takoyaki/2796.jpg  \n",
      "  inflating: uecfood10/takoyaki/2797.jpg  \n",
      "  inflating: uecfood10/takoyaki/2798.jpg  \n",
      "  inflating: uecfood10/takoyaki/2799.jpg  \n",
      "  inflating: uecfood10/takoyaki/2800.jpg  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  inflating: uecfood10/takoyaki/2801.jpg  \n",
      "  inflating: uecfood10/takoyaki/2802.jpg  \n",
      "  inflating: uecfood10/takoyaki/2803.jpg  \n",
      "  inflating: uecfood10/takoyaki/2804.jpg  \n",
      "  inflating: uecfood10/takoyaki/2805.jpg  \n",
      "  inflating: uecfood10/takoyaki/2806.jpg  \n",
      "  inflating: uecfood10/takoyaki/2807.jpg  \n",
      "  inflating: uecfood10/takoyaki/2808.jpg  \n",
      "  inflating: uecfood10/takoyaki/2809.jpg  \n",
      "  inflating: uecfood10/takoyaki/2810.jpg  \n",
      "  inflating: uecfood10/takoyaki/2811.jpg  \n",
      "  inflating: uecfood10/takoyaki/2812.jpg  \n",
      "  inflating: uecfood10/takoyaki/2813.jpg  \n",
      "  inflating: uecfood10/takoyaki/2814.jpg  \n",
      "  inflating: uecfood10/takoyaki/2815.jpg  \n",
      "  inflating: uecfood10/takoyaki/2816.jpg  \n",
      "  inflating: uecfood10/takoyaki/2817.jpg  \n",
      "  inflating: uecfood10/takoyaki/2818.jpg  \n",
      "  inflating: uecfood10/takoyaki/2819.jpg  \n",
      "  inflating: uecfood10/takoyaki/2820.jpg  \n",
      "  inflating: uecfood10/takoyaki/2821.jpg  \n",
      "  inflating: uecfood10/takoyaki/2822.jpg  \n",
      "  inflating: uecfood10/takoyaki/2823.jpg  \n",
      "  inflating: uecfood10/takoyaki/2824.jpg  \n",
      "  inflating: uecfood10/takoyaki/2825.jpg  \n",
      "  inflating: uecfood10/takoyaki/2826.jpg  \n",
      "  inflating: uecfood10/takoyaki/2827.jpg  \n",
      "  inflating: uecfood10/takoyaki/2828.jpg  \n",
      "  inflating: uecfood10/takoyaki/2829.jpg  \n",
      "  inflating: uecfood10/takoyaki/2830.jpg  \n",
      "  inflating: uecfood10/takoyaki/2831.jpg  \n",
      "  inflating: uecfood10/takoyaki/2832.jpg  \n",
      "  inflating: uecfood10/takoyaki/2833.jpg  \n",
      "  inflating: uecfood10/takoyaki/2834.jpg  \n",
      "  inflating: uecfood10/takoyaki/2835.jpg  \n",
      "  inflating: uecfood10/takoyaki/2836.jpg  \n",
      "  inflating: uecfood10/takoyaki/2837.jpg  \n",
      "  inflating: uecfood10/takoyaki/2838.jpg  \n",
      "  inflating: uecfood10/takoyaki/2839.jpg  \n",
      "  inflating: uecfood10/takoyaki/2840.jpg  \n",
      "  inflating: uecfood10/takoyaki/2841.jpg  \n",
      "  inflating: uecfood10/takoyaki/2842.jpg  \n",
      "  inflating: uecfood10/takoyaki/2843.jpg  \n",
      "  inflating: uecfood10/takoyaki/2844.jpg  \n",
      "  inflating: uecfood10/takoyaki/2845.jpg  \n",
      "  inflating: uecfood10/takoyaki/2846.jpg  \n",
      "  inflating: uecfood10/takoyaki/2847.jpg  \n",
      "  inflating: uecfood10/takoyaki/2848.jpg  \n",
      "  inflating: uecfood10/takoyaki/2849.jpg  \n",
      "  inflating: uecfood10/takoyaki/2850.jpg  \n",
      "  inflating: uecfood10/takoyaki/2851.jpg  \n",
      "  inflating: uecfood10/takoyaki/2852.jpg  \n",
      "  inflating: uecfood10/takoyaki/2853.jpg  \n",
      "  inflating: uecfood10/takoyaki/2854.jpg  \n",
      "  inflating: uecfood10/takoyaki/2855.jpg  \n",
      "  inflating: uecfood10/takoyaki/2856.jpg  \n",
      "  inflating: uecfood10/takoyaki/2857.jpg  \n",
      "  inflating: uecfood10/takoyaki/2858.jpg  \n",
      "  inflating: uecfood10/takoyaki/2859.jpg  \n",
      "  inflating: uecfood10/takoyaki/2860.jpg  \n",
      "  inflating: uecfood10/takoyaki/2861.jpg  \n",
      "  inflating: uecfood10/takoyaki/2862.jpg  \n",
      "  inflating: uecfood10/takoyaki/2863.jpg  \n",
      "  inflating: uecfood10/takoyaki/2864.jpg  \n",
      "  inflating: uecfood10/takoyaki/2865.jpg  \n",
      "  inflating: uecfood10/takoyaki/2866.jpg  \n",
      "  inflating: uecfood10/takoyaki/2867.jpg  \n",
      "  inflating: uecfood10/takoyaki/2868.jpg  \n",
      "  inflating: uecfood10/takoyaki/2869.jpg  \n",
      "  inflating: uecfood10/takoyaki/2870.jpg  \n",
      "  inflating: uecfood10/takoyaki/2871.jpg  \n"
     ]
    }
   ],
   "source": [
    "!setenv http_proxy http://proxy.uec.ac.jp:8080/\n",
    "!wget http://mm.cs.uec.ac.jp/uecfood10.zip\n",
    "!unzip uecfood10.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ResNet50, DenseNet, MobileNetV2で，3枚以上の画像について，それぞれ1000種類認識を行うこと．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 640564\r\n",
      "-rw------- 1 yamamoto-k YANAI_LAB 102502400 Apr 19 00:11 resnet50-19c8e357.pth\r\n",
      "-rw------- 1 yamamoto-k YANAI_LAB 553433881 Apr 19 00:11 vgg16-397923af.pth\r\n"
     ]
    }
   ],
   "source": [
    "resnet50 = models.resnet50(pretrained=True,progress=True)\n",
    "softmax=nn.Softmax(dim=1)\n",
    "# pretrained=True とすると，学習済みポラメータも読み込まれる．\n",
    "# ~/.cache/torch/checkpoints/ の下に読み込まれます．\n",
    "# ls でダウンロードされていることを確認してみます．\n",
    "! ls -l ~/.cache/torch/checkpoints/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img=np.array(Image.open('animal/cat/458000.jpg').resize((224,224)), dtype=np.float32)\n",
    "mean=np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "std=np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "img=(img/255.0-mean)/std\n",
    "img=img.transpose(2,0,1)  # HWC -> CHW\n",
    "img=img[np.newaxis,...]  # adding batch axis\n",
    "img=torch.from_numpy(img)\n",
    "\n",
    "resnet50.eval() \n",
    "# batch_normalization を eval modelで計算するために，model.eval()で\n",
    "# eval modeを設定する．(学習時の平均分散を利用．)　\n",
    "# train modeだと，batch内の平均分散が使われるが，\n",
    "# この場合 batch_size=1 でbatch内平均分散が計算され，正しくない結果になる．\n",
    "# batch normalization を使ったモデルで認識する場合は，evel modeへの\n",
    "# 切り替えは必須なので，注意すること．\n",
    "\n",
    "with torch.no_grad(): # 勾配計算はしないので，no_grad modeで計算\n",
    "    out=softmax(resnet50(img)).numpy()[0]\n",
    "    # numpy()で，Tensor形式から numpy形式に変換\n",
    "    # batch_size=1 で1枚だけ認識したので，1枚目の結果だけをoutに入れるために[0]がついている\n",
    "\n",
    "top5   =np.sort(out)[:-6:-1]      # 昇順にソートされるので，最後の5つが top5\n",
    "top5idx=np.argsort(out)[:-6:-1]   # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.41984814 n02123045 tabby, tabby cat\n",
      "[2] 0.36664221 n02124075 Egyptian cat\n",
      "[3] 0.11454849 n02123159 tiger cat\n",
      "[4] 0.01690814 n04235860 sleeping bag\n",
      "[5] 0.00552601 n04033995 quilt, comforter, comfort, puff\n"
     ]
    }
   ],
   "source": [
    "# 認識結果の top-5 の結果の表示\n",
    "SYNSET_FILE='images/synset_words.txt'  # ImageNet1000 種類のカテゴリ名が書かれたファイル．\n",
    "synset=open(SYNSET_FILE).read().split('\\n')\n",
    "for i in range(5):\n",
    "    print(\"[%d] %.8f %s\" % (i+1,top5[i],synset[top5idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.58431989 n02389026 sorrel\n",
      "[2] 0.05341934 n03538406 horse cart, horse-cart\n",
      "[3] 0.04868601 n02109047 Great Dane\n",
      "[4] 0.02667153 n02397096 warthog\n",
      "[5] 0.02404747 n03803284 muzzle\n"
     ]
    }
   ],
   "source": [
    "# 画像の変換は, TorchVisionを使うと簡単にできます．\n",
    "import torchvision.transforms as transforms\n",
    "image_size = (224, 224) \n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "image_transform = transforms.Compose([transforms.Resize(image_size),transforms.ToTensor(),normalize])\n",
    "img = Image.open('animal/horse/197000.jpg')\n",
    "img = image_transform(img)\n",
    "img = img.unsqueeze(0)\n",
    "resnet50.eval() \n",
    "with torch.no_grad(): \n",
    "    out=softmax(resnet50(img)).numpy()[0]\n",
    "top5   =np.sort(out)[:-6:-1]   \n",
    "top5idx=np.argsort(out)[:-6:-1] \n",
    "for i in range(5):\n",
    "    print(\"[%d] %.8f %s\" % (i+1,top5[i],synset[top5idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.35583398 n02071294 killer whale, killer, orca, grampus, sea wolf, Orcinus orca\n",
      "[2] 0.32056576 n02981792 catamaran\n",
      "[3] 0.08331214 n04273569 speedboat\n",
      "[4] 0.06607159 n02066245 grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus\n",
      "[5] 0.05940937 n04483307 trimaran\n"
     ]
    }
   ],
   "source": [
    "# 画像の変換は, TorchVisionを使うと簡単にできます．\n",
    "import torchvision.transforms as transforms\n",
    "image_size = (224, 224) \n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "image_transform = transforms.Compose([transforms.Resize(image_size),transforms.ToTensor(),normalize])\n",
    "img = Image.open('animal/whale/314000.jpg')\n",
    "img = image_transform(img)\n",
    "img = img.unsqueeze(0)\n",
    "resnet50.eval() \n",
    "with torch.no_grad(): \n",
    "    out=softmax(resnet50(img)).numpy()[0]\n",
    "top5   =np.sort(out)[:-6:-1]   \n",
    "top5idx=np.argsort(out)[:-6:-1] \n",
    "for i in range(5):\n",
    "    print(\"[%d] %.8f %s\" % (i+1,top5[i],synset[top5idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /home/yanai-lab/yamamoto-k/.cache/torch/checkpoints/densenet121-a639ec97.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32342954.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total 672152\n",
      "-rw------- 1 yamamoto-k YANAI_LAB  32342954 Apr 19 11:38 densenet121-a639ec97.pth\n",
      "-rw------- 1 yamamoto-k YANAI_LAB 102502400 Apr 19 00:11 resnet50-19c8e357.pth\n",
      "-rw------- 1 yamamoto-k YANAI_LAB 553433881 Apr 19 00:11 vgg16-397923af.pth\n"
     ]
    }
   ],
   "source": [
    "resnet50 = models.densenet121(pretrained=True,progress=True)\n",
    "softmax=nn.Softmax(dim=1)\n",
    "# pretrained=True とすると，学習済みポラメータも読み込まれる．\n",
    "# ~/.cache/torch/checkpoints/ の下に読み込まれます．\n",
    "# ls でダウンロードされていることを確認してみます．\n",
    "! ls -l ~/.cache/torch/checkpoints/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img=np.array(Image.open('animal/cat/458000.jpg').resize((224,224)), dtype=np.float32)\n",
    "mean=np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "std=np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "img=(img/255.0-mean)/std\n",
    "img=img.transpose(2,0,1)  # HWC -> CHW\n",
    "img=img[np.newaxis,...]  # adding batch axis\n",
    "img=torch.from_numpy(img)\n",
    "\n",
    "resnet50.eval() \n",
    "# batch_normalization を eval modelで計算するために，model.eval()で\n",
    "# eval modeを設定する．(学習時の平均分散を利用．)　\n",
    "# train modeだと，batch内の平均分散が使われるが，\n",
    "# この場合 batch_size=1 でbatch内平均分散が計算され，正しくない結果になる．\n",
    "# batch normalization を使ったモデルで認識する場合は，evel modeへの\n",
    "# 切り替えは必須なので，注意すること．\n",
    "\n",
    "with torch.no_grad(): # 勾配計算はしないので，no_grad modeで計算\n",
    "    out=softmax(resnet50(img)).numpy()[0]\n",
    "    # numpy()で，Tensor形式から numpy形式に変換\n",
    "    # batch_size=1 で1枚だけ認識したので，1枚目の結果だけをoutに入れるために[0]がついている\n",
    "\n",
    "top5   =np.sort(out)[:-6:-1]      # 昇順にソートされるので，最後の5つが top5\n",
    "top5idx=np.argsort(out)[:-6:-1]   # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.57403105 n02124075 Egyptian cat\n",
      "[2] 0.15738159 n02123045 tabby, tabby cat\n",
      "[3] 0.02562893 n04235860 sleeping bag\n",
      "[4] 0.02446591 n04418357 theater curtain, theatre curtain\n",
      "[5] 0.01973881 n02356798 fox squirrel, eastern fox squirrel, Sciurus niger\n"
     ]
    }
   ],
   "source": [
    "# 認識結果の top-5 の結果の表示\n",
    "SYNSET_FILE='images/synset_words.txt'  # ImageNet1000 種類のカテゴリ名が書かれたファイル．\n",
    "synset=open(SYNSET_FILE).read().split('\\n')\n",
    "for i in range(5):\n",
    "    print(\"[%d] %.8f %s\" % (i+1,top5[i],synset[top5idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.49551272 n02389026 sorrel\n",
      "[2] 0.10558570 n02109047 Great Dane\n",
      "[3] 0.05545345 n03868242 oxcart\n",
      "[4] 0.03781640 n02403003 ox\n",
      "[5] 0.03221358 n02087394 Rhodesian ridgeback\n"
     ]
    }
   ],
   "source": [
    "# 画像の変換は, TorchVisionを使うと簡単にできます．\n",
    "import torchvision.transforms as transforms\n",
    "image_size = (224, 224) \n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "image_transform = transforms.Compose([transforms.Resize(image_size),transforms.ToTensor(),normalize])\n",
    "img = Image.open('animal/horse/197000.jpg')\n",
    "img = image_transform(img)\n",
    "img = img.unsqueeze(0)\n",
    "resnet50.eval() \n",
    "with torch.no_grad(): \n",
    "    out=softmax(resnet50(img)).numpy()[0]\n",
    "top5   =np.sort(out)[:-6:-1]   \n",
    "top5idx=np.argsort(out)[:-6:-1] \n",
    "for i in range(5):\n",
    "    print(\"[%d] %.8f %s\" % (i+1,top5[i],synset[top5idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.54365867 n02071294 killer whale, killer, orca, grampus, sea wolf, Orcinus orca\n",
      "[2] 0.23112325 n02066245 grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus\n",
      "[3] 0.08728761 n04483307 trimaran\n",
      "[4] 0.03937368 n04612504 yawl\n",
      "[5] 0.02063609 n04273569 speedboat\n"
     ]
    }
   ],
   "source": [
    "# 画像の変換は, TorchVisionを使うと簡単にできます．\n",
    "import torchvision.transforms as transforms\n",
    "image_size = (224, 224) \n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "image_transform = transforms.Compose([transforms.Resize(image_size),transforms.ToTensor(),normalize])\n",
    "img = Image.open('animal/whale/314000.jpg')\n",
    "img = image_transform(img)\n",
    "img = img.unsqueeze(0)\n",
    "resnet50.eval() \n",
    "with torch.no_grad(): \n",
    "    out=softmax(resnet50(img)).numpy()[0]\n",
    "top5   =np.sort(out)[:-6:-1]   \n",
    "top5idx=np.argsort(out)[:-6:-1] \n",
    "for i in range(5):\n",
    "    print(\"[%d] %.8f %s\" % (i+1,top5[i],synset[top5idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /home/yanai-lab/yamamoto-k/.cache/torch/checkpoints/mobilenet_v2-b0353104.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364f2c46250d40dfa0074e6f597c126a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14212972.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total 686032\n",
      "-rw------- 1 yamamoto-k YANAI_LAB  32342954 Apr 19 11:38 densenet121-a639ec97.pth\n",
      "-rw------- 1 yamamoto-k YANAI_LAB  14212972 Apr 19 11:40 mobilenet_v2-b0353104.pth\n",
      "-rw------- 1 yamamoto-k YANAI_LAB 102502400 Apr 19 00:11 resnet50-19c8e357.pth\n",
      "-rw------- 1 yamamoto-k YANAI_LAB 553433881 Apr 19 00:11 vgg16-397923af.pth\n"
     ]
    }
   ],
   "source": [
    "resnet50 = models.mobilenet_v2(pretrained=True,progress=True)\n",
    "softmax=nn.Softmax(dim=1)\n",
    "# pretrained=True とすると，学習済みポラメータも読み込まれる．\n",
    "# ~/.cache/torch/checkpoints/ の下に読み込まれます．\n",
    "# ls でダウンロードされていることを確認してみます．\n",
    "! ls -l ~/.cache/torch/checkpoints/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img=np.array(Image.open('animal/cat/458000.jpg').resize((224,224)), dtype=np.float32)\n",
    "mean=np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "std=np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "img=(img/255.0-mean)/std\n",
    "img=img.transpose(2,0,1)  # HWC -> CHW\n",
    "img=img[np.newaxis,...]  # adding batch axis\n",
    "img=torch.from_numpy(img)\n",
    "\n",
    "resnet50.eval() \n",
    "# batch_normalization を eval modelで計算するために，model.eval()で\n",
    "# eval modeを設定する．(学習時の平均分散を利用．)　\n",
    "# train modeだと，batch内の平均分散が使われるが，\n",
    "# この場合 batch_size=1 でbatch内平均分散が計算され，正しくない結果になる．\n",
    "# batch normalization を使ったモデルで認識する場合は，evel modeへの\n",
    "# 切り替えは必須なので，注意すること．\n",
    "\n",
    "with torch.no_grad(): # 勾配計算はしないので，no_grad modeで計算\n",
    "    out=softmax(resnet50(img)).numpy()[0]\n",
    "    # numpy()で，Tensor形式から numpy形式に変換\n",
    "    # batch_size=1 で1枚だけ認識したので，1枚目の結果だけをoutに入れるために[0]がついている\n",
    "\n",
    "top5   =np.sort(out)[:-6:-1]      # 昇順にソートされるので，最後の5つが top5\n",
    "top5idx=np.argsort(out)[:-6:-1]   # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.64548445 n04418357 theater curtain, theatre curtain\n",
      "[2] 0.10899960 n03958227 plastic bag\n",
      "[3] 0.10550346 n02123045 tabby, tabby cat\n",
      "[4] 0.03398220 n02124075 Egyptian cat\n",
      "[5] 0.02855452 n02123159 tiger cat\n"
     ]
    }
   ],
   "source": [
    "# 認識結果の top-5 の結果の表示\n",
    "SYNSET_FILE='images/synset_words.txt'  # ImageNet1000 種類のカテゴリ名が書かれたファイル．\n",
    "synset=open(SYNSET_FILE).read().split('\\n')\n",
    "for i in range(5):\n",
    "    print(\"[%d] %.8f %s\" % (i+1,top5[i],synset[top5idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.89574432 n02389026 sorrel\n",
      "[2] 0.02672737 n02403003 ox\n",
      "[3] 0.01726714 n03538406 horse cart, horse-cart\n",
      "[4] 0.01323690 n03868242 oxcart\n",
      "[5] 0.01040322 n02087394 Rhodesian ridgeback\n"
     ]
    }
   ],
   "source": [
    "# 画像の変換は, TorchVisionを使うと簡単にできます．\n",
    "import torchvision.transforms as transforms\n",
    "image_size = (224, 224) \n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "image_transform = transforms.Compose([transforms.Resize(image_size),transforms.ToTensor(),normalize])\n",
    "img = Image.open('animal/horse/197000.jpg')\n",
    "img = image_transform(img)\n",
    "img = img.unsqueeze(0)\n",
    "resnet50.eval() \n",
    "with torch.no_grad(): \n",
    "    out=softmax(resnet50(img)).numpy()[0]\n",
    "top5   =np.sort(out)[:-6:-1]   \n",
    "top5idx=np.argsort(out)[:-6:-1] \n",
    "for i in range(5):\n",
    "    print(\"[%d] %.8f %s\" % (i+1,top5[i],synset[top5idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 0.53851748 n02066245 grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus\n",
      "[2] 0.26376879 n02071294 killer whale, killer, orca, grampus, sea wolf, Orcinus orca\n",
      "[3] 0.04305320 n01494475 hammerhead, hammerhead shark\n",
      "[4] 0.03277330 n04147183 schooner\n",
      "[5] 0.02058468 n02058221 albatross, mollymawk\n"
     ]
    }
   ],
   "source": [
    "# 画像の変換は, TorchVisionを使うと簡単にできます．\n",
    "import torchvision.transforms as transforms\n",
    "image_size = (224, 224) \n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "image_transform = transforms.Compose([transforms.Resize(image_size),transforms.ToTensor(),normalize])\n",
    "img = Image.open('animal/whale/314000.jpg')\n",
    "img = image_transform(img)\n",
    "img = img.unsqueeze(0)\n",
    "resnet50.eval() \n",
    "with torch.no_grad(): \n",
    "    out=softmax(resnet50(img)).numpy()[0]\n",
    "top5   =np.sort(out)[:-6:-1]   \n",
    "top5idx=np.argsort(out)[:-6:-1] \n",
    "for i in range(5):\n",
    "    print(\"[%d] %.8f %s\" % (i+1,top5[i],synset[top5idx[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 上記のデータセットで，VGG16をfine-tuningして，画像分類を行うこと．データ拡張しない場合と，する場合を比較せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まず，image_transform を定義します．ImageFolderで指定するので，先に\n",
    "# 定義しておく必要があります．\n",
    "imgdir=\"./uecfood10\"\n",
    "\n",
    "# リサイズ，CHW変換，正規化 の標準的な image_transform\n",
    "image_size = (224, 224) \n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "image_transform = transforms.Compose([transforms.Resize(image_size),transforms.ToTensor(),normalize])\n",
    "\n",
    "# リサイズ，CHW変換，正規化 に加えて，+-20度のランダム回転，\n",
    "# 0.8-1.2倍のランダム縦横比変換＋0.7-1.0倍のランダムクロップ，ランダム左右反転，のデータ拡張ありの image_transform\n",
    "image_transform_aug = transforms.Compose([transforms.RandomRotation(20),\n",
    "                                          transforms.RandomResizedCrop(image_size, scale=(0.7, 1.0), ratio=(0.8, 1.2)),\n",
    "                                          transforms.RandomHorizontalFlip(), transforms.ToTensor(), normalize\n",
    "                                        ])\n",
    "\n",
    "# ImageFolfer では，クラス毎にディレクトリがあって，そのクラスの画像が入っていることを想定しています．\n",
    "# animal/lion/*.jpg, animal/dog/*.jpg, animal/cat/*.jpg  ....のような感じです．\n",
    "#   animal datasetは，まさにそのようになっています．\n",
    "dataset=torchvision.datasets.ImageFolder(root=imgdir, transform=image_transform) \n",
    "\n",
    "# データ拡張ありの場合は，以下のを用いる． image_transform -> image_transform_aug\n",
    "augmentation=True # データ拡張しない場合は False，拡張する場合は True にする．\n",
    "\n",
    "if augmentation:\n",
    "    # データ拡張あり (学習データのみ)\n",
    "    dataset2=torchvision.datasets.ImageFolder(root=imgdir, transform=image_transform_aug) \n",
    "else:\n",
    "    # データ拡張なし\n",
    "    dataset2=dataset\n",
    "    \n",
    "num = len(dataset) # animal datasetの場合，1000\n",
    "\n",
    "# indexの作成．5で割り切れない数がtestのindex, 5の倍数がtrainのindex.\n",
    "# つまり，train:text=4:1=80%:20% とする．\n",
    "train_idx=[n for n in range(num) if n%5!=0]\n",
    "test_idx =[n for n in range(num) if n%5==0]\n",
    "\n",
    "trainset  = torch.utils.data.dataset.Subset(dataset2, train_idx)\n",
    "testset   = torch.utils.data.dataset.Subset(dataset, test_idx)\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc:  0.89\n",
      "Time:  110.19336771965027\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epoch=25\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1, min_lr=0.00001)\n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "show_graph=ShowGraph(num_epoch)\n",
    "show_graph.on_train_begin();\n",
    "\n",
    "def train():\n",
    "    loss=0\n",
    "    total=0\n",
    "    total0=0\n",
    "    correct=0\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        outputs = model(inputs.to(device))\n",
    "        labels=labels.to(device)\n",
    "        loss0= loss_fn(outputs, labels)\n",
    "        loss+= loss0.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        total0+=1\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss0.backward()\n",
    "        optimizer.step()\n",
    "    loss=loss/total0\n",
    "    acc=correct/total \n",
    "    return loss, acc\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "         vloss=0\n",
    "         total2=0\n",
    "         total20=0\n",
    "         correct2=0\n",
    "         for (inputs, labels) in testloader:\n",
    "             outputs = model(inputs.to(device))\n",
    "             labels=labels.to(device)\n",
    "             vloss += loss_fn(outputs, labels).item()\n",
    "             _, predicted = torch.max(outputs.data, 1)\n",
    "             total2 += labels.size(0)\n",
    "             total20+=1\n",
    "             correct2 += (predicted == labels).sum().item()\n",
    "         vloss=vloss/total20\n",
    "         vacc=correct2/total2\n",
    "    return vloss, vacc   \n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    l, a = train()   \n",
    "    lv, av = validate()\n",
    "    scheduler.step(lv) # val_lossが下がらなければlrを下げる\n",
    "    show_graph.on_epoch_end(epoch,l,a,lv,av)\n",
    "            \n",
    "del show_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ拡張なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まず，image_transform を定義します．ImageFolderで指定するので，先に\n",
    "# 定義しておく必要があります．\n",
    "imgdir=\"./uecfood10\"\n",
    "\n",
    "# リサイズ，CHW変換，正規化 の標準的な image_transform\n",
    "image_size = (224, 224) \n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "image_transform = transforms.Compose([transforms.Resize(image_size),transforms.ToTensor(),normalize])\n",
    "\n",
    "# リサイズ，CHW変換，正規化 に加えて，+-20度のランダム回転，\n",
    "# 0.8-1.2倍のランダム縦横比変換＋0.7-1.0倍のランダムクロップ，ランダム左右反転，のデータ拡張ありの image_transform\n",
    "image_transform_aug = transforms.Compose([transforms.RandomRotation(20),\n",
    "                                          transforms.RandomResizedCrop(image_size, scale=(0.7, 1.0), ratio=(0.8, 1.2)),\n",
    "                                          transforms.RandomHorizontalFlip(), transforms.ToTensor(), normalize\n",
    "                                        ])\n",
    "\n",
    "# ImageFolfer では，クラス毎にディレクトリがあって，そのクラスの画像が入っていることを想定しています．\n",
    "# animal/lion/*.jpg, animal/dog/*.jpg, animal/cat/*.jpg  ....のような感じです．\n",
    "#   animal datasetは，まさにそのようになっています．\n",
    "dataset=torchvision.datasets.ImageFolder(root=imgdir, transform=image_transform) \n",
    "\n",
    "# データ拡張ありの場合は，以下のを用いる． image_transform -> image_transform_aug\n",
    "augmentation=False # データ拡張しない場合は False，拡張する場合は True にする．\n",
    "\n",
    "if augmentation:\n",
    "    # データ拡張あり (学習データのみ)\n",
    "    dataset2=torchvision.datasets.ImageFolder(root=imgdir, transform=image_transform_aug) \n",
    "else:\n",
    "    # データ拡張なし\n",
    "    dataset2=dataset\n",
    "    \n",
    "num = len(dataset) # animal datasetの場合，1000\n",
    "\n",
    "# indexの作成．5で割り切れない数がtestのindex, 5の倍数がtrainのindex.\n",
    "# つまり，train:text=4:1=80%:20% とする．\n",
    "train_idx=[n for n in range(num) if n%5!=0]\n",
    "test_idx =[n for n in range(num) if n%5==0]\n",
    "\n",
    "trainset  = torch.utils.data.dataset.Subset(dataset2, train_idx)\n",
    "testset   = torch.utils.data.dataset.Subset(dataset, test_idx)\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=10)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc:  0.92\n",
      "Time:  107.79639291763306\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAEWCAYAAACKZoWNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZwcdZ3/8ddnjtwhIXdIAgkIAUQIJGSVQwEXTJDlWDAcwgoqwXVRcJWFeAK/dWVXRHSVIyIqxwIBRFAjJCC3IEkg4Y5JMJDJQSaBhNzJTD6/P7496Z6enpmema6p6pr38/Hox9TZ9eme/tan6lvf+pa5OyIiIpIuFXEHICIiIqWnBC8iIpJCSvAiIiIppAQvIiKSQkrwIiIiKaQELyIikkJK8CIiKWdmS83sH+OOQzqXEryIiEgKKcFLJCzQ70tEJCbaAaecmV1hZkvMbIOZvW5mp+XMu9DM3siZd1hm+igz+62Z1ZrZWjP7WWb6lWZ2R876o83MzawqM/6EmX3fzJ4FNgN7m9kFOdt4y8wuyovvFDObb2YfZOKcZGafMbN5ect93cx+F903JZJ+ZtbdzK43sxWZ1/Vm1j0zb5CZ/cHM1pnZe2b2dMNBupldbmbLM+V4oZl9Mt5PIsWoijsAidwS4GhgFfAZ4A4z+xBwFHAlcCowF9gH2GFmlcAfgD8D5wH1wIQ2bO88YDKwEDBgLHAS8BbwceBPZjbH3V80s4nAbcAZwGPAcKAv8HfgZjM7wN3fyLzvucB/tucLEJFdvgV8FBgHOPAg8G3gO8DXgRpgcGbZjwJuZmOBi4HD3X2FmY0GKjs3bGkPncGnnLvf6+4r3H2nu98DLAImAl8E/sfd53iw2N3fzszbA7jM3Te5+1Z3f6YNm/y1u7/m7nXuvsPd/+juSzLbeBKYRTjgAPgCcKu7z87Et9zd33T3bcA9hKSOmX0YGE048BCR9vsscLW7r3b3WuAqwkE5wA7CQfZembL7tIeHldQD3YEDzaza3Ze6+5JYopc2UYJPOTP7l0wV+DozWwccBAwCRhHO7vONAt5297p2bnJZ3vYnm9nzmSq/dcCJme03bKu5HcVvgHPMzAg7oBmZxC8i7bcH8HbO+NuZaQA/BBYDszKX064AcPfFwKWEGr/VZna3me2BJJ4SfIqZ2V7ALwjVawPdvT/wKqHqfBmhWj7fMmDPhuvqeTYBvXLGhxVYZtfjCTPX9u4HrgWGZrY/M7P9hm0VigF3fx7YTjjbPwe4vfCnFJE2WAHslTO+Z2Ya7r7B3b/u7nsD/wT8e8O1dnf/P3c/KrOuA//duWFLeyjBp1tvQmGsBTCzCwhn8AC3AN8ws/GZFu8fyhwQvACsBK4xs95m1sPMjsysMx/4uJntaWb9gGmtbL8boWqvFqgzs8nACTnzfwlcYGafNLMKMxthZvvnzL8N+BlQ18bLBCJS2F3At81ssJkNAr4L3AFgZidl9gMGfEComq83s7FmdlzmgH0rsCUzTxJOCT7F3P114EfAc8C7wEeAZzPz7gW+D/wfsAH4HTDA3esJR+8fAt4hNLo5M7PObMK18ZeBebRyTdzdNwBfBWYA7xPOxB/Kmf8CcAHwY2A98CSNzy5uJxyQ6OxdpDT+k9Co9mXgFeBFso1X9wUeBTYS9hk3uPsThIP0a4A1hMa6Q4BvdmrU0i4W2lCIJI+Z9QRWA4e5+6K44xERKSc6g5ck+1dgjpK7iEjbRXYfvJndSrj/ebW7H1RgvgE/IbSq3gyc7+4vRhWPlBczW0pojHdqzKFIG2T+bxsI12jr3L0tfSiISAlF2dHNrwkNpG5rZv5kwjWffYF/AG7M/BXB3UfHHYO027HuvibuIES6usiq6N39KeC9FhY5Bbgt0wHK80B/MxseVTwiIiJdSZxd1Y6gcacoNZlpK/MXNLOpwFSA3r17j99///3zF5FOsmQJrFsHvXrB2LFQUYJDxI0b4a23YMeO5pepqoL+/WHUqLZvs74+xLxhA2zZErazcye4Z18tqaiAbt2gb18YMgR69Gjb9iFsc8sW2LoVtm8PL7MQR11diLG+Pow3xFZVFbZVVQWVldm/DcM9ekDPns1vc968eWvcfXDzS0TCCR2lOHCzu0/PX0DlWaRt2luW40zwVmBawV1tZicxHWDChAk+d+7cKOOSHLfcAhddFJJOrs2b4aWXsuNmcOSR8Kc/QZ8+Td/n73+Ha6+Fp5+Gd96B9evbFkddHaxZE16dbefOkJi3boXa2ui2U1kZDiQaEvfQoWH4/ffD6733woFBgwsugFtvbf79zOzt5udG5shMf+VDgNlm9mamNm8XlWeRtmlvWY4zwdcQuiptMJJMj0oSnw8+gOHDQwJvTkVF04TvDs88E85y26OyEv7hH2D27FA70OCxx+Bb34JXXglnwO29q7OyEqqrQ+LcfXfYc084+mj4x3+Ej340JNZCduyA22+He+6BV18NSXbbtmwcVugwNaO6Opus+/aFfv1g8ODw/Y4aBePGwUEHhVi6d2/9M7iH7+C990LC79277d9D1Ny9oVe01Wb2AOHZBk+1vJaIRCHOBP8QcLGZ3U1oXLfe3ZtUz0vxli6FMWPC8AEHwOuvF7/uX/8aEl0hZvD//l9ItIVMnw5f+1rLBwW5qqpCYnv22cbJvJBPfjK84lJdDZ//fHjFzSx8X716wciRcUfTlJn1BircfUNm+ATg6pjDEumyImtkZ2Z3EXpDGmtmNWb2BTP7kpl9KbPITMIjRBcT+kv/clSxJN2ZZ4ZEYpZ9PfZY8euvWxfWaUjuAG+8kX2vV15pft1f/Sosk5/cjzkme316587mkzvA1KmwaVPja9otvXbsCNX7rSV3KTtDgWfMbAGhy+M/uvvDMcck0mWVXU92ha7Z7dixg5qaGrZu3RpTVMXZsQNWtPEiRGVl9mytR48ejBw5kurq6l3zq6pC46xcQ4fCu+82fa9DDoH588Pwl78MN97YdJlly5J5dihtZ2bzkn4fuq7BSzHKZR/fUYX28dD+shxnFX3J1NTU0LdvX0aPHo21dFE0Rg37sEGDWl6uT5/QqjzXpk0ATu/ea6mpqWHMmDH06xeul+e66y4466zs+P33wxlnZMcXLCh8zbiiIlzT3W23Yj+NiEjnKYd9fEe5O2vXZvfxpZCKBL9169bE/uMXLWraYnzvvWHAgNbXXbAg99YxY/XqgaxeXcveezde7mtfg+uua7r+6adnG4MNG9b0rL5nz+Kvm4uIxCXJ+/hSMTMGDhxIbQlv1UlFggcS94+vq8tWhzfo2zfcO16sQw4Jf9etg8WLAazRPeBHHRVuOyvGqlXh7+23h1urHn+8+DhEROKWtH18FEr9GVOT4JNk3rymt3NN6MCV0P79s+vPnh1qAJYsad97nXdeeImISLrpaXIlsG7dOm644QYWLQrX2nOT+0EHNZ/cTzzxRNatW9embY0c2f7kLiIibdewj2+r9uzjS0kJvgRqa9fxox/d0Ohae+/ecOih9S12azpz5kz69+8ffYAiItJuzSX4+vxbmPLEvY9XFX0HzZsH06ZdwfLlSzjnnHFUVVUzdGgfhg8fzvz583n99dc59dRTWbZsGVu3buWSSy5h6tSpAIwePZq5c+eyceNGJk+ezFFHHcVf/vIXRowYwYMPPkjPljoaFxGRTnHFFVewZMkSxo0bR3V1NX36lMc+PnUJ/tJLmzZu66hx4+D66xtPe+ut0GUowMUXX8OSJa8yb9585s17gk9/+tO8+uqru251uPXWWxkwYABbtmzh8MMP5/TTT2fgwIGN3m/RokXcdddd/OIXv2DKlCncf//9nHvuuaX9ICIiZa6z9vG5rrnmGl599VXmz5/PE0+Uzz4+dQk+ajt2hNvXcnXvnu1vHGDixImN7mP86U9/ygMPPADAsmXLWLRoUZN//pgxYxg3bhwA48ePZ+nSpZF9BhERab9y2cenLsG3dBTWUQsXhkeO5powIfQBn6t3zlNAnnjiCR599FGee+45evXqxTHHHFOwN6buOU8bqaysZMuWLaUMXUQkFaLcxxerXPbxqUvwUdmxo3FyHzs2e8bet29fNuRn/oz169ez++6706tXL958802ef/75TohWRERKpVz38UrwRcqtls+/7W3gwIEceeSRHHTQQfTs2ZOhQ4fumjdp0iRuuukmDj74YMaOHctHm3tkm4iIJFK57uNT8bCZN954gwMOOCCybb74Yvb557ln7nGI+rNKeuhhM5IWXWm/V+iztrcs6z74Vqxbl03uFRXxJncREZFiKcG3IvQBHxx2WHxxiIiItIUSfAtyaw470pe8iIhIZ1OCb8bf/pYdVrW8iIiUGyX4ZnzwQXa4LY94FRERSQIl+AJUNS8iIuVOCT7PSy9lhz/0oeLWae+jBAGuv/56Nm/e3K51IzFxYrgmUWa3T4qIRKVc9/FdKsGvWRPOzlt6NTz9zwyKfcpfuf7zAbj88vBhG15z5sDGjeGeQBERKdt9fJfqya4tffuPH1/8srmPEjz++OMZMmQIM2bMYNu2bZx22mlcddVVbNq0iSlTplBTU0N9fT3f+c53ePfdd1mxYgXHHnssgwYN4vHHH2/zZ2qzV14J9/vV1bW+rJnO5EWkyyurfXyO9CX4Zp4luHkLjC0ipwH06QNYzoRWniWY+yjBWbNmcd999/HCCy/g7px88sk89dRT1NbWsscee/DHP/4RCP0X9+vXj+uuu47HH3+cQYMGteFDtsP69c1XSVRUwC23wAUXhPE774SGxxgqyYtIksTwvNiy2McX0GXqYetzknvfvi2/zJp/n9bMmjWLWbNmceihh3LYYYfx5ptvsmjRIj7ykY/w6KOPcvnll/P000/Tr1+/wm/gnr1OUCpVVU2T+z//c9hWw/YakjvAZz8L3/lO4/XbYv36eA8K3EMMIiIl1uF9fCdK3xl8gaOwVaugpiYMR90q3t2ZNm0aF110UZN58+bNY+bMmUybNo0TTjiB7373u9mZdXXFHZWuWQMHHpgdP/dcuP32wsv279800T38MHzqU61v5+qr4e234bbbwgFA796waVPL60yfDrmf+3Ofg1//uvVtldLo0SFugOHD4e9/h5zHNIpImYv5ebHt3sfHoEucwTck96jkPkrwUyecwK233srGjRsBWL58OatXr2bFihX06tWLc889l2984xu8+OKL2XWffbb9VU533JFtIFdRAX/8Y7hx36xxcv/e98KZbTHJvcFvfgNHHRWGN2+GIUMKL/fss2F7+T/43/wmTP/f/23bZ2qPj388bKshuQOsXAk9esChh0a/fRFJrUb7+E99qu37+GYeNRu19J3B58ltvHjIIdFsY9ejBPfZh8lHHME5Rx3Fx8aNg8pK+gwYwB133MHixYu57LLLqKiooLq6mhtvvBHmzWPqpElMvuQShg8axOM33QT77gstVe288UZI1HffDeec07gq3B1OOqnx8iedBL//ffs/3NNPw377waJFUFsLBxwQYoDQ2n633RrH0LNn+NIb1gH46lfD64kn4BOfaH8shZx/fjiQaGAGM2aEWo5DDsnWjJjBqafCAw+UdvttsX49XHUV/Pa3sHw5jBoFZ58N//qvMHJkfHGJSItyHxc7efJkzjnnHD72sY8B0KdPn+b38cDUqVOZPHkyw4cP7/RGdql/XGyndFpT7OMu99oLBg8OCSe/FfuwYUXt5Jv9rFOmwL33ZsdHjw7V06UyaBCsXRuGjzkmnLXv2JGdX1ERElifPo3X69evcbeAZuGaSXO1AcW69lq47LLG0666CvKrxB54AE4/vfFByH/8B/z3f3ds+8Worw+XLW6+ORwUbd+enZffeLFv33B3w5lnhksbvXp1ePN6XKykhR4X276ynOoz+Nz8s/feRayQu6Pp3h0+8pGWl899UHyDPfaA6urGVcUN3n676fS+fUvTF+6MGR1/j5asWROSzpYt4Uw816JFzfcKtH59uHbfv384qHGHoUNLG9tZZ8FddxWed9pp4X/0X/8F3/pWmPY//xNee+8N99xT2iO/++6DK6+EhQubHsTtvjscfXQ4CBk/Phz43HIL3H8/LFgATz4ZXl/+cviOxo0LB4XNOeKIcDAgIlJAqhP8ggXZ4QEDWlhw3rymrb63bWuc8IcODVWqEO4l37at8fK77RaqpRsMHpwdXrgQ8q/BVFdHd80gKps3hxb1Da38Z8yAz3ym9fV69w5HW6tXlza5T5gQOuYpxje/GV7nnhtuAwR46y04/PAwXF0dku+997byY8nz2mvwla/A88+Hg59c3bqFs/JLLw1n5vl22w3+/d/DC2DJErjpJpg5Mxw0Pfdc4x9xvl69lOBFpFmpSfDujjVzf9vAgc2s9NJLTW9Ja661+Lvvhle+bt3g4INbDi7/DN29XffiJeJySl1duPaeXxVfjCFDwmffvh0qK8Ors91xR3jNng1f+lK4jOEeDkD+/Ofsj6V795Zb3+/Y0TShm4X1zzgDfvzj0MCvLfbZB374w/CC8NuM4zsSSaCW9vFpUep9fCoSfI8ePVi7di0DBw7c9QPIPfkeMyZvhddfb9z6DppP1EuWwPvvN51u1rbu7vLXbSN3Z+3atfRoa9KIQnuSe65u3UoTR0ccf3z43za49tpQjd/wv962rWktTSG9e8ORR4Y7BXJrcEpByV0EKLyPT5so9vGpSPAjR46kpqaG2traXdPWrAl/q6uzjb5Zt67pfeFmsOeeYXjXgnl6984Ob9wYxs2aXz4iPXr0YKRaW0fjG98ILwg1DLfdFq6ZN2fQoHALoZKwSOQK7ePTqNT7+FQk+OrqasbknKY3tAWDnEvrN98cqmRzJaHKW5KnWzf44hfjjkJEMvL38VKcVCT4fA3JfbfdMhMarrc2UGIXEZGUi7QnOzObZGYLzWyxmV1RYP5eZvaYmb1sZk+YWYfrJnJvh1u/ntAw7oQTshOV3EUiZWaVZvaSmf0h7lhEurLIEryZVQI/ByYDBwJnm9mBeYtdC9zm7gcDVwM/6Oh2G/p22fU482HDsjOV3EU6wyVA5zZQEZEmojyDnwgsdve33H07cDdwSt4yBwKPZYYfLzC/TU4+OTtcX0/j1uqrVnXkrUWkCJlauE8Dt8Qdi0hXF2WCHwEsyxmvyUzLtQA4PTN8GtDXzJrctW5mU81srpnNbakVZaMu13OT+6xZpe89TUQKuR74D2BncwsUW55FpGOiTPCFblbMryP/BvAJM3sJ+ASwHKhrspL7dHef4O4TBuf2ENcMz930D38Y7nkWkUiZ2UnAanef19JybS3PItI+UbairwFG5YyPBFbkLuDuK4B/BjCzPsDp7p53o3rbnMzvsiP/8i/Ze5tFJGpHAieb2YlAD2A3M7vD3c+NOS6RLinKM/g5wL5mNsbMugFnAQ/lLmBmg8ysIYZpwK0d2eDJPMjdnB1GPvaxxo8RFZFIufs0dx/p7qMJ5f3PSu4i8Ykswbt7HXAx8AihRe0Md3/NzK42s4bmcMcAC83sb8BQ4Pvt3qAZd/JZ3mUoDB8Of/lLxz6AiIhIGYu0oxt3nwnMzJv23Zzh+4D7OryhTHehG+nDCTzC31aU4PGrItJu7v4E8ETMYYh0aZF2dNMpevfe9Uz2T/Ewi1ByFxERKe8EP3Jko6fCvcy4GIMRERFJjvJN8BMnwvLl2XH1UiciIrJLeSb4Cy+EOXOy40ruIiIijZRfgq+thVtyesFUchcREWmi/BL8O+9kh3OS+8MPxxCLiIhIQpVfgm+Qd+b+05/GFIeIiEgClWeCL1AtP3duDHGIiIgkVPkl+PHjC05et66T4xAREUmw8kvwzdixI+4IREREkiM1CV5ERESylOBFRERSSAleREQkhVKX4M3ijkBERCR+qUvw3brFHYGIiEj8Upfghw6NOwIREZH4pS7BH3983BGIiIjEL3UJ/j//M+4IRERE4pe6BD9sWNwRiIiIxC91CV5ERESU4EVERFJJCV5ERCSFlOBFRERSSAleREQkhZTgRUREUkgJXkREJIWU4EVERFJICV5ERCSFlOBFRERSKBUJ/k9/ijsCERGRZElFgv/+9+OOQEREJFlSkeBffz3uCERERJIlFQl+w4a4IxAREUmWVCT4urq4IxAREUmWSBO8mU0ys4VmttjMrigwf08ze9zMXjKzl83sxCjjEZHomFkPM3vBzBaY2WtmdlXcMYl0ZZEleDOrBH4OTAYOBM42swPzFvs2MMPdDwXOAm6IKh4Ridw24Dh3PwQYB0wys4/GHJNIlxXlGfxEYLG7v+Xu24G7gVPylnFgt8xwP2BFhPGISIQ82JgZrc68PMaQRLq0KBP8CGBZznhNZlquK4FzzawGmAl8pdAbmdlUM5trZnNra2ub3aBZh+IVkQ4ys0ozmw+sBma7+18LLFNUeRaRjokywRdKt/lH82cDv3b3kcCJwO1m1iQmd5/u7hPcfcLgwYOb3WDPnh0JV0Q6yt3r3X0cMBKYaGYHFVimqPIsIh1TVII3s/vN7NOFkm8LaoBROeMjaVoF/wVgBoC7Pwf0AAa1YRuNjMivHxCRWLj7OuAJYFLMoYh0WcUm7BuBc4BFZnaNme1fxDpzgH3NbIyZdSM0onsob5l3gE8CmNkBhATf7jq7E9UGXyQ2ZjbYzPpnhnsC/wi8GW9UIl1XUQne3R91988ChwFLgdlm9hczu8DMqptZpw64GHgEeIPQWv41M7vazE7OLPZ14EIzWwDcBZzv7u1ulHNFkxvxRKQTDQceN7OXCQf4s939DzHHJNJlVRW7oJkNBM4FzgNeAu4EjgI+BxxTaB13n0loPJc77bs5w68DR7Y16OYMG1aqdxKRtnL3l4FD445DRIKiEryZ/RbYH7gd+Cd3X5mZdY+ZzY0qOBEREWmfYs/gf+bufy40w90nlDAeERERKYFiG9kd0NB4BsDMdjezL0cUk4iIiHRQsQn+wsxtLwC4+/vAhdGEJCIiIh1VbIKvMMv2E5fpZ75bNCGJiIhIRxV7Df4RYIaZ3UToje5LwMORRSUiIiIdUmyCvxy4CPhXQhe0s4BbogpKREREOqaoBO/uOwm92d0YbTgiIiJSCsXeB78v8APCc917NEx3970jiktEREQ6oNhGdr8inL3XAccCtxE6vREREZEEKjbB93T3xwBz97fd/UrguOjCKt4NN8QdgUj6mNklZrabBb80sxfN7IS44xKR4hWb4LdmHhW7yMwuNrPTgCERxlW06dPjjkAklT7v7h8AJwCDgQuAa+INSUTaotgEfynQC/gqMJ7w0JnPRRVUWyxdGncEIqnU0O/FicCv3H1BzjQRKQOtNrLLdGozxd0vAzYSjuQTY8OGuCMQSaV5ZjYLGANMM7O+wM6YYxKRNmg1wbt7vZmNNzPryLPao7JTuxyRKHwBGAe85e6bzWwACTu4F5GWFdvRzUvAg2Z2L7CpYaK7/zaSqEQkbh8D5rv7JjM7FzgM+EnMMYlIGxR7DX4AsJbQcv6fMq+TogpKRGJ3I7DZzA4B/gN4m3B7rIiUiWJ7slPVnEjXUufubmanAD9x91+aWSIa1opIcYrtye5XhIfMNOLuny95RO1UUWxdhIgUY4OZTQPOA47ONLatjjkmEWmDYq/B/yFnuAdwGrCi9OG0X+/ecUcgkipnAucQ7odfZWZ7Aj+MOSYRaYNiq+jvzx03s7uARyOJqJ322ivuCETSI5PU7wQON7OTgBfcXdfgRcpIeyu29wX2LGUgHfXZz8YdgUh6mNkU4AXgM8AU4K9mdka8UYlIWxR7DX4Dja/BryI8Iz4xrrgi7ghEUuVbwOHuvhrAzAYTau3uizUqESlasVX0faMOREQSpaIhuWespf01fiISg6IKrJmdZmb9csb7m9mp0YUlIjF72MweMbPzzex84I/AzJhjEpE2KPaI/Hvuvr5hxN3XAd+LJiQRiVvm2RPTgYOBQ4Dp7p6oy3Ii0rJib5MrdCBQ7LoiUoYyd8/c3+qCIpJIxSbpuWZ2HfBzQmO7rwDzIotKRGJRoEHtrlmAu/tunRySiLRTsQn+K8B3gHsy47OAb0cSkYjERg1qRdKj2Fb0mwDdiCYiIlImim1FP9vM+ueM725mj0QXloiIiHREsa3oB2VazgPg7u8DQ6IJSURERDqq2AS/M/OwCQDMbDSFG+KIiIhIAhTbyO5bwDNm9mRm/OPA1GhCKt6qVXFHICIikkzFNrJ72MwmEJL6fOBBYEuUgRXj17+OOwIREZFkKvZhM18ELgFGEhL8R4HngONaWW8S8BOgErjF3a/Jm/9j4NjMaC9giLv3p0h33lnskiISNTMbBdwGDAN2Enq/+0m8UYl0XcVeg78EOBx4292PBQ4FaltawcwqCR3jTAYOBM42swNzl3H3r7n7OHcfB/wv8Nu2BL90aVuWFpGI1QFfd/cDCCcB/5Zf5kWk8xSb4Le6+1YAM+vu7m8CY1tZZyKw2N3fcvftwN3AKS0sfzZwV5HxALB5c1uWFpEouftKd38xM7wBeAMYEW9UIl1XsQm+JnMf/O+A2Wb2ILCilXVGAMty34NmCruZ7QWMAf7czPypZjbXzObW1mYrDnbuLDJ6EelUmTttDgX+WmBewfIsIqVVVIJ399PcfZ27X0nosvaXQGuPi7VCb9XMsmcB97l7fTPbn+7uE9x9wuDBg4sJWURiYmZ9CA+pudTdP8ifr/Is0jna/EQ4d3+y9aWAcMY+Kmd8JM2f9Z8F/FtbYxGRZDGzakJyv9Pd29SmRkRKq9gq+vaYA+xrZmPMrBshiT+Uv5CZjQV2J7TKF5EyZWZGqN17w92vizseka4usgTv7nXAxcAjhMY2M9z9NTO72sxOzln0bOBud293z3gVUR6miEixjgTOA44zs/mZ14lxByXSVbW5ir4t3H0mMDNv2nfzxq/s6Hb66gGXIrFz92co3PZGRGKQinPf/faLOwIREZFkSUWCP//8uCMQERFJllQk+C9/Oe4IREREkiUVCV5EREQaU4IXERFJISV4ERGRFFKCFxERSSEleBERkRRSgheR2LzyStwRiKSXEryIxGb79rgjEEkvJXgREZEUUoIXERFJISV4ERGRFCrbBL9qVVRio0kAAA9aSURBVNwRiIiIJFfZJvhrrok7AhEphYkT445AJJ3KNsH//vdxRyAipTBnTtwRiKRT2Sb4lSvjjkBERCS5yjbBb90adwQiIiLJVbYJ3j3uCERERJKrbBO8iIiINE8JXkRip9teRUpPCV5EYnfYYXFHIJI+ZZ/gq6rijkBEOkp3xYiUXtkn+H794o5AREQkeco+wR9ySNwRiEh7jRkTdwQi6VX2Cf6yy+KOQETaa8CAuCMQSa+yT/CTJsUdgYiISPKUfYIXkXSYPz/uCETSRQleRBLhyCPjjkAkXZTgRSQRNm+OOwKRdFGCF5FY9ekTdwQi6aQELyKxevrpuCMQSScleBGJ1bhxcUcgkk5K8CIiIikUaYI3s0lmttDMFpvZFc0sM8XMXjez18zs/6KMR0SiY2a3mtlqM3u1ve9xww2ljEika4sswZtZJfBzYDJwIHC2mR2Yt8y+wDTgSHf/MHBpVPGISOR+DXSo66mvfKU0gYhItGfwE4HF7v6Wu28H7gZOyVvmQuDn7v4+gLuvjjAeEYmQuz8FvNeR99i5s0TBiEikCX4EsCxnvCYzLdd+wH5m9qyZPW9mBY/+zWyqmc01s7m1tbWsWhVRxCISufzyDDAif88gIh0WZYK3AtM8b7wK2Bc4BjgbuMXM+jdZyX26u09w9wmDBw/m618veawi0knyyzPA3LkxByWSQlEm+BpgVM74SGBFgWUedPcd7v53YCEh4bfomWdKFqOIJMCwYXFHIJI+USb4OcC+ZjbGzLoBZwEP5S3zO+BYADMbRKiyf6u1N3733RJHKiIikjKRJXh3rwMuBh4B3gBmuPtrZna1mZ2cWewRYK2ZvQ48Dlzm7mtbe+/t26OKWkTay8zuAp4DxppZjZl9oT3vc+GFpY1LpKsy9/zL4sk2YcIEnzcve8GuzMIX6TRmNs/dJ8QdR0smTJjgczMX4C2n1Y7KtUhWe8uyerITERFJISV4EUkEPQ9epLSU4EUkEXR3jEhplXWC79Yt7ghERESSqawTfL9+cUcgIiKSTGWd4Cckun2wiLTXUUfFHYFI+SvrBP9f/xV3BCIShWefjTsCkfJX1gl+3Li4IxAREUmmsk7wIpIul1wSdwQi6aEELyKJcf31cUcgkh5K8CIiIimkBC8iibRqVdwRiJQ3JXgRic+iRc3O0m2wIh2jBC8i8fngg2ZnLV/eiXGIpJASvIjEK/c5sUBVVUxxiKSMEryIxO+aa3YN3n57jHGIpIgSvIjEb9q0XYNnnRVjHCIpogQvIvEZPz47nFdVLyIdU3YJfvPmuCMQkZIaMSI7/PDDjWbNn9/JsYikSNkl+JUr445AREqqpiY7PHlyo1lHH93JsYikSNkl+E2b4o5AREou98i9R49dgxs3xhCLSEqUXYKvq4s7AhEpuWHDoHv3MLxtG32rs9fi7r03pphEylzZJXj3uCMQkUhs3bprcN2O3ruGp0yB/faLIyCR8lZ2CV5EUuxPfwLCjsmH77Fr8qJFamQv0lZK8CKSHJMmZTP5ypVNauyU5EWKpwQvIsmyc2d22AzHmMUn6c6Whkm8/HJMsYmUkbJN8DqSF0mxH/yg0ejx/Jkt9GIh+/FjLuWXh1zPn+yT8O67MQUoknzmZdZqzWyCw1y6dYNt2+KORiS5zGyeuyf6oasTJkzwuXPntrzQoEGwdi0ADtRRRTXhdppN9GQnlfRlY2iJr44yJIXaW5bL9rlNgwfHHYGIdIo1a3YNGlB9881M+1ItW+jNUTzLsTweZq5axWobQi2D6M1GRh89Gp56KpaQRZKgbBP8Jz4RdwQiEouLLuIHF4X2eD955GtUsIPj+DNH8DxH8BeO5ml6sYX6p5ez0frRnW10ZxslvarXsyeceSb86lelfFeRkirbKvqVK0ONnIgUlpoq+jY4+GBY9coKTuNBDmM+FdRTTxWV1DOQtYziHfZnYajST4OKCqisDL3/9egBffvCwIGw557w4Q+HM6HDDw/TO2LTJli9Gt55B9atC20f1qwJw2vXQm1tmL9+fVh282bYvj30TLZzZzgg6tkzxNGvX9h5jxoFY8eGBw7tvTfsvnujXgwlq71luWwTfJmFLdLpumKCz/eDH8A3v9nyMt27hwOD226D/fdvZqG1a+Fzn4PZs0PiEslXWZkdLtQKfPToML3hVVHRePzRR2Ho0IJv3eWuwYuItGbatOyj5mtrYciQpsts2wZz5sABBzT/PlVVA3nqqT/wsT9EE2dBS5fCCy/A3LmwYAGsWBEONDZtCkHX1UF9fScG1IrcxFVZCVVVUF0dxt1hx47wqq8PZ/Xu0XRNWii5NsTV3DKVldkEnRtXw9+KilC7kD8vd/7AgY3XyV9m4sTGn9u98XhV6dOxEryIdAmDBzfe9+62G2zYUNy6dXVwxBGNp/XpE3Jww3695EaPDq8pUyLagKRd2d4HLyLSER980PhkqtBr4cLmLwtv3Bju4MutZU3Kq6oqXO7ec0/4zGfC55CuJ9IzeDObBPwEqARucfdr8uafD/wQWJ6Z9DN3vyXKmEQkOq2V+XKz336wZUvjaffcA+ec07jDvaSprw8HIBs3wrJlcN99nbPd3Fr6hhr6ysoQz7ZtjWvnC60LjddtaDfYp08Yrq4O86qqQtuJ6urwGjIktNkbNgyGDw/De+0V1su3Y0doC7h2bTjI27gx1ORs3hzGN2zIthVsmN6jR/gt7L57OKgbNChcLh82LNQEtVduTX1lZek7cIsswZtZJfBz4HigBphjZg+5++t5i97j7hdHFYeIdI42lPmyduaZ4RWldevg6qvhd78LCWzQoJDExo7NNo7fc8+wbE0NXHstPP10SOYffBCSWBwHILkJq66u0QMCi1oXwkFAwwHBxo2NukEoaz16ZA9udu5seqCzbBmMHFnabUZ5Bj8RWOzubwGY2d3AKUCqCruI7KIyXyL9+8N114VXa0aOhOuvjz6mQlavhocfhiVL4G9/C3fRvfdeOMjYsiXccLBzJ/TuHc5+hwyBffaBww6DT38aPvSh7HvNnx/6JVqwILRtWLkyHOhs3ty4/VuhdmoNZ7757fcahisqmjZaz61t6NYtnO1XV4fhhr89emRrCnr0CAccmzeHz7ZlSzgI2b49vM/w4dnPUqiG4rjjstvLfTVM60hNQHMiu03OzM4AJrn7FzPj5wH/kHu2nqmi/wFQC/wN+Jq7LyvwXlOBqZnRg4BXIwm6dAYBST7uTHp8kPwYkx4fwFh37+AN0MUrpsxnppdTeS6H/3PSY0x6fJD8GNtVlqM8gy90NSH/aOL3wF3uvs3MvgT8BjiuyUru04HpAGY2N+n39iY9xqTHB8mPMenxQYixszdZYFqTM4hyKs9Jjw+SH2PS44Pkx9jeshxlK/oaYFTO+EhgRe4C7r7W3RseGfMLYHyE8YhItFot8yLSeaJM8HOAfc1sjJl1A84CHspdwMxyrlpwMvBGhPGISLRaLfMi0nkiq6J39zozuxh4hHDLzK3u/pqZXQ3MdfeHgK+a2clAHfAecH4Rbz09qphLKOkxJj0+SH6MSY8POjnG5sp8K6sl/XtMenyQ/BiTHh8kP8Z2xVd2fdGLiIhI69STnYiISAopwYuIiKRQWSV4M5tkZgvNbLGZXRF3PPnMbKmZvWJm82O4RakgM7vVzFab2as50waY2WwzW5T5u3sCY7zSzJZnvsv5ZnZijPGNMrPHzewNM3vNzC7JTE/E99hCfIn5DvMlvSyDynMJ40vM7zDpZbmVGNv8PZbNNfhMN5h/I6cbTODsJHWDaWZLgQnunpgOE8zs48BG4DZ3Pygz7X+A99z9mszOdXd3vzxhMV4JbHT3a+OKq0Hmbo/h7v6imfUF5gGnEhqFxv49thDfFBLyHeYqh7IMKs8ljO9KEvI7THpZbiXGNpfncjqD39UNprtvBxq6wZQWuPtThDsUcp1C6FSIzN9TOzWoPM3EmBjuvtLdX8wMbyDczjmChHyPLcSXVCrL7ZT08qyy3HGlLM/llOBHALnd2NaQvJ2YA7PMbJ6F7jiTaqi7r4TwYwKGxBxPcy42s5cz1X6xXkZoYGajgUOBv5LA7zEvPkjgd0h5lGVQeS6lxP0Ok16WoePluZwSfFHdYMbsSHc/DJgM/Fumukra50ZgH2AcsBL4UbzhgJn1Ae4HLnX3D+KOJ1+B+BL3HWaUQ1kGledSSdzvMOllGUpTnsspwSe+G0x3X5H5uxp4gFAVmUTvZq7zNFzvWR1zPE24+7vuXu/uOwndGMf6XZpZNaGw3enuv81MTsz3WCi+pH2HORJflkHluVSS9jtMelnOxFCS8lxOCT7R3WCaWe9MgwjMrDdwAsl9StZDwOcyw58DHowxloKscTfGpxHjd2lmBvwSeMPdcx/gmYjvsbn4kvQd5kl0WQaV51JK0u8w6WUZSlye3b1sXsCJhNa3S4BvxR1PXmx7Awsyr9eSEh9wF6E6ZwfhzOkLwEDgMWBR5u+ABMZ4O/AK8DKh8A2PMb6jCFXILwPzM68Tk/I9thBfYr7DAjEntixn4lN5Ll18ifkdJr0stxJjm7/HsrlNTkRERIpXTlX0IiIiUiQleBERkRRSghcREUkhJXgREZEUUoIXERFJISV46RRmdoyZ/SHuOESkY1SWy4cSvIiISAopwUsjZnaumb2Qed7wzWZWaWYbzexHZvaimT1mZoMzy44zs+czDz94oOHhB2b2ITN71MwWZNbZJ/P2fczsPjN708zuzPTYJCIRUFkWJXjZxcwOAM4kPGRjHFAPfBboDbzo4cEbTwLfy6xyG3C5ux9M6GGpYfqdwM/d/RDgCELPVhCeinQpcCChp7AjI/9QIl2QyrIAVMUdgCTKJ4HxwJzMAXlPwkMXdgL3ZJa5A/itmfUD+rv7k5npvwHuzfTfPcLdHwBw960Amfd7wd1rMuPzgdHAM9F/LJEuR2VZlOClEQN+4+7TGk00+07eci31b9xSVd22nOF69PsTiYrKsqiKXhp5DDjDzIYAmNkAM9uL8Ds5I7PMOcAz7r4eeN/Mjs5MPw940sNzi2vM7NTMe3Q3s16d+ilERGVZdNQlWe7+upl9G5hlZhWEJ0L9G7AJ+LCZzQPWE67tQXis4k2ZQv8WcEFm+nnAzWZ2deY9PtOJH0Oky1NZFkBPk5PWmdlGd+8Tdxwi0jEqy12LquhFRERSSGfwIiIiKaQzeBERkRRSghcREUkhJXgREZEUUoIXERFJISV4ERGRFPr/XgiSM+vSgEAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epoch=25\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1, min_lr=0.00001)\n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "show_graph=ShowGraph(num_epoch)\n",
    "show_graph.on_train_begin();\n",
    "\n",
    "def train():\n",
    "    loss=0\n",
    "    total=0\n",
    "    total0=0\n",
    "    correct=0\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        outputs = model(inputs.to(device))\n",
    "        labels=labels.to(device)\n",
    "        loss0= loss_fn(outputs, labels)\n",
    "        loss+= loss0.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        total0+=1\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss0.backward()\n",
    "        optimizer.step()\n",
    "    loss=loss/total0\n",
    "    acc=correct/total \n",
    "    return loss, acc\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "         vloss=0\n",
    "         total2=0\n",
    "         total20=0\n",
    "         correct2=0\n",
    "         for (inputs, labels) in testloader:\n",
    "             outputs = model(inputs.to(device))\n",
    "             labels=labels.to(device)\n",
    "             vloss += loss_fn(outputs, labels).item()\n",
    "             _, predicted = torch.max(outputs.data, 1)\n",
    "             total2 += labels.size(0)\n",
    "             total20+=1\n",
    "             correct2 += (predicted == labels).sum().item()\n",
    "         vloss=vloss/total20\n",
    "         vacc=correct2/total2\n",
    "    return vloss, vacc   \n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    l, a = train()   \n",
    "    lv, av = validate()\n",
    "    scheduler.step(lv) # val_lossが下がらなければlrを下げる\n",
    "    show_graph.on_epoch_end(epoch,l,a,lv,av)\n",
    "            \n",
    "del show_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
